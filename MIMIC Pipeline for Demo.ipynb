{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2b1de5c-9f12-45cd-88b8-87464b841d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import re\n",
    "import random\n",
    "import pickle\n",
    "import subprocess\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f711066d-fb43-42d7-810d-3624404b69b6",
   "metadata": {},
   "source": [
    "# 1. Setup concept extractors\n",
    "\n",
    "Some options were [MetaMap](https://metamap.nlm.nih.gov/) and [spaCy](https://spacy.io/). \n",
    "\n",
    "[MetaMap](https://metamap.nlm.nih.gov/) is specific to recognizing UMLS concepts. There is a [Python wrapper](https://github.com/AnthonyMRios/pymetamap), but known to be slow and bad.\n",
    "\n",
    "[spaCy](https://spacy.io/) is a popular NLP Python package with an extensive library for named entity recognition. It has a wide variety of [extensions](https://spacy.io/universe) and models to choose from. We're going with the following.\n",
    "\n",
    "* [scispaCy](https://spacy.io/universe/project/scispacy) contains spaCy models for processing biomedical, scientific or clinical text. It seems easy to use and has a wide variety of concepts it can recognize, including UMLS, RxNorm, etc.\n",
    "\n",
    "* [negspaCy](https://spacy.io/universe/project/negspacy) identifies negations using some extension of regEx. Probably useful for things like, \"this pt is diabetic\" v. \"this pt is not diabetic.\" [todo: negation identification of medspacy might be better, https://github.com/medspacy/medspacy]\n",
    "\n",
    "* [Med7](https://github.com/kormilitzin/med7) is a model trained for recognizing entities in prescription text, e.g. identifies drug name, dosage, duration, etc., which could be useful stuff to check for conflicts. \n",
    "\n",
    "We're going with spaCy for this.. and coming up with a coherent way to integrate entities picked up by these three extensions/models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71301789-8d31-49ed-87af-bcb2215da50c",
   "metadata": {},
   "source": [
    "## i) Installations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aae2d503-cff3-4fe2-9fbe-e003b28420e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/opt/conda/envs/opennotes/bin/python'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys; sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33f9000b-8678-4718-88d4-e41ffefcec41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('2.3.5', '0.3.0')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "import scispacy\n",
    "\n",
    "from pprint import pprint\n",
    "from collections import OrderedDict\n",
    "\n",
    "from spacy import displacy\n",
    "# from scispacy.abbreviation import AbbreviationDetector # UMLS already contains abbrev. detect\n",
    "from scispacy.umls_linking import UmlsEntityLinker\n",
    "\n",
    "# should be 2.3.5 and >=0.3.0\n",
    "spacy.__version__, scispacy.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68518fa6-6403-4c67-ae66-0553f50ab89b",
   "metadata": {},
   "source": [
    "## ii) Setting up the model\n",
    "\n",
    "The model is used to form word/sentence embeddings for the NER task. Thus, it's important to choose model that has been tuned for our specific use case (e.g. clinical text, prescription information) so the embeddings are useful for naming the entity.\n",
    "\n",
    "[Note to self:] one potential idea to look into if we have time remaining, something about using custom model for spacy pipeline (could we do smth with the romanov models since they've been trained specifically for conflict detection?) -- https://spacy.io/usage/v3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475a77b2-fee6-456b-8413-c21f8788c584",
   "metadata": {},
   "source": [
    "### a) scispaCy\n",
    "\n",
    "For scispaCy, we set up one of their models that has been trained on biomedical data. Other models can be found [here](https://allenai.github.io/scispacy/). \n",
    "\n",
    "We load two models since we will be linking different entity linkers (knowledge bases that link text to named entites) later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f41850bf-6cb2-41f0-a88e-3f0ca7398f3c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "## uncomment to install model if not already installed\n",
    "# !/opt/conda/envs/opennotes/bin/python -m pip install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.2.5/en_core_sci_sm-0.2.5.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "efb3aa0e-d096-45dc-b3ee-13baf63a3d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for umls (general biomedical concepts)\n",
    "umls_nlp   = spacy.load(\"en_core_sci_sm\")\n",
    "\n",
    "# for rxnorm (prescriptions)\n",
    "rxnorm_nlp = spacy.load(\"en_core_sci_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f8bb022-64b3-4969-b880-6eb717c612a6",
   "metadata": {},
   "source": [
    "### b) Med7\n",
    "\n",
    "For Med7, we set up their model that has been trained specifically for NER of medication-related concepts: dosage, drug names, duration, form, frequency, route of administration, and strength. The model is trained on MIMIC-III, so it should work well for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9672e962-d666-466c-8b5c-4de36d4342f2",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # installs Med7 model\n",
    "# !pip install https://www.dropbox.com/s/xbgsy6tyctvrqz3/en_core_med7_lg.tar.gz?dl=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8786df8a-342d-4f5c-852c-d784902bc321",
   "metadata": {},
   "outputs": [],
   "source": [
    "med7_nlp = spacy.load(\"en_core_med7_lg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "663387a7-1da0-4e39-80e6-534426b6a2f4",
   "metadata": {},
   "source": [
    "## iii) Adding an entity linker\n",
    "\n",
    "The EntityLinker is a spaCy component that links to a knowledge base. The linker compares words with the concepts in the specified knowledge base (e.g. scispaCy's UMLS does some form of character overlap-based nearest neighbor search, has option to resolve abbreviations first).\n",
    "\n",
    "[Note: Entities generally get resolved to a list of different entities. This [blog post](http://sujitpal.blogspot.com/2020/08/disambiguating-scispacy-umls-entities.html) describes one potential way to disambiguate this by figuring out \"most likely\" set of entities. Gonna start off with just resolving to the 1st entity tho... hopefully that's sufficient.]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06cd7515-edfb-4442-885b-f52d0e5d4e27",
   "metadata": {},
   "source": [
    "### a) scispaCy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e405baf0-4cd0-4416-bfd1-17f600be0c93",
   "metadata": {},
   "source": [
    "#### UMLS Linker\n",
    "\n",
    "UMLS linker maps entities to the UMLS concept. Main parts we'll be interested in are: semantic type and concept (mainly the common name, maybe the CUI might become important later).\n",
    "\n",
    "* _Semantic type_ is the broader category that the entity falls under, e.g. disease, pharmacologic substance, etc. See [this](https://metamap.nlm.nih.gov/Docs/SemanticTypes_2018AB.txt) for a full list.\n",
    "\n",
    "* _Concepts_ refer to the more fundamental entity itself, e.g. pneumothorax, ventillator, etc. Many concepts can fall under a semantic type.\n",
    "\n",
    "More info on `UmlsEntityLinker` ([source code](https://github.com/allenai/scispacy/blob/4ade4ec897fa48c2ecf3187caa08a949920d126d/scispacy/linking.py#L9))\n",
    "\n",
    "See source code for `.jsonl` file with the knowledge base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc71654d-e023-42dc-b9e6-9421f40561b0",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/opennotes/lib/python3.7/site-packages/sklearn/base.py:315: UserWarning: Trying to unpickle estimator TfidfTransformer from version 0.20.3 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/envs/opennotes/lib/python3.7/site-packages/sklearn/base.py:315: UserWarning: Trying to unpickle estimator TfidfVectorizer from version 0.20.3 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "from scispacy.umls_linking import UmlsEntityLinker\n",
    "\n",
    "# abbreviation_pipe = AbbreviationDetector(nlp) # automatically included with UMLS linker\n",
    "# nlp.add_pipe(abbreviation_pipe)\n",
    "umls_linker = UmlsEntityLinker(k=10,                          # number of nearest neighbors to look up from\n",
    "                               threshold=0.7,                 # confidence threshold to be added as candidate\n",
    "                               max_entities_per_mention=1,    # number of entities returned per concept (todo: tune)\n",
    "                               filter_for_definitions=False,  # no definition is OK\n",
    "                               resolve_abbreviations=True)    # resolve abbreviations before linking\n",
    "umls_nlp.add_pipe(umls_linker)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa91b326-b714-4698-b21c-0ef098048593",
   "metadata": {},
   "source": [
    "#### RxNorm Linker\n",
    "\n",
    "RxNorm linker maps entities to RxNorm, an ontology for clinical drug names. It contains about 100k concepts for normalized names for clinical drugs. It is comprised of several other drug vocabularies commonly used in pharmacy management and drug interaction, including First Databank, Micromedex, and the Gold Standard Drug Database.\n",
    "\n",
    "More info on `RxNorm` ([NIH page](https://www.nlm.nih.gov/research/umls/rxnorm/index.html), [source code](https://github.com/allenai/scispacy/blob/2290a80cfe0948e48d8ecfbd60064019d57a6874/scispacy/linking_utils.py#L120))\n",
    "\n",
    "See source code for `.jsonl` file with the knowledge base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c98a726f-4515-49d0-914c-b8593278a8b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/opennotes/lib/python3.7/site-packages/sklearn/base.py:315: UserWarning: Trying to unpickle estimator TfidfTransformer from version 0.22.2.post1 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/envs/opennotes/lib/python3.7/site-packages/sklearn/base.py:315: UserWarning: Trying to unpickle estimator TfidfVectorizer from version 0.22.2.post1 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "from scispacy.linking import EntityLinker\n",
    "\n",
    "# rxnorm_linker = EntityLinker(resolve_abbreviations=True, name=\"rxnorm\")\n",
    "rxnorm_linker = EntityLinker(k=10,                          # number of nearest neighbors to look up from\n",
    "                             threshold=0.7,                 # confidence threshold to be added as candidate\n",
    "                             max_entities_per_mention=1,    # number of entities returned per concept (todo: tune)\n",
    "                             filter_for_definitions=False,  # no definition is OK\n",
    "                             resolve_abbreviations=True,    # resolve abbreviations before linking\n",
    "                             name=\"rxnorm\")                 # RxNorm ontology\n",
    "\n",
    "rxnorm_nlp.add_pipe(rxnorm_linker)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5a2032-9dcb-4c1d-ae02-c2785f7b7fca",
   "metadata": {},
   "source": [
    "### b) Med7 \n",
    "\n",
    "No need for entity linker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5697e483-5a37-4431-a57b-96a25a988832",
   "metadata": {},
   "source": [
    "### c) Negspacy [TODO]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f5053d-0f84-476e-b425-9335f2fc6912",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cf6c212a-fc0c-486f-b52c-6193e78842fc",
   "metadata": {},
   "source": [
    "# 2. Setup data structures\n",
    "\n",
    "## Categorizing type of conflict\n",
    "\n",
    "The first larger task is to categorize by the type of conflict to check for since our method will likely be different (at least for the rule based). We wrote up a short list [here](https://docs.google.com/document/d/1fEBk0JHeyQWshYWW5w_VTkaYyRfm9MBxJ9DAGoVa8Yw/edit?usp=sharing). \n",
    "\n",
    "To do this, we're using the semantic type that is identified by the UMLS linker. Here's a table of the semantic types we're filtering for, and which conflict they'll be used for.\n",
    "\n",
    "Here's a [full list](https://metamap.nlm.nih.gov/Docs/SemanticTypes_2018AB.txt) of semantic types. You can look up definitions of semantic types [here](http://linkedlifedata.com/resource/umls-semnetwork/T033).\n",
    "\n",
    "| Conflict | Semantic Type |\n",
    "| --- | ----------- |\n",
    "| Diagnoses-related errors | Disease or Syndrome (T047), Diagnostic Procedure(T060) |\n",
    "| Inaccurate description of medical history (symptoms) | Sign or Symptom (T184) |\n",
    "| Inaccurate description of medical history (operations) | Therapeutic or Preventive Procedure (T061) |\n",
    "| Inaccurate description of medical history (other) | [all of the above and below] |\n",
    "| Medication or allergies | Clinical Drug (T200), Pharmacologic Substance (T121) |\n",
    "| Test procedures or results | Laboratory Procedure (T059), Laboratory or Test Result (T034) | \n",
    "\n",
    "\n",
    "For clarity, the concepts we'll keep from the UMLS linker are anything falling into these semantic types (which we will then categorize by type of conflict using the table above):\n",
    "\n",
    "* T047 - Disease or Syndrome\n",
    "* T121 - Pharmacologic Substance\n",
    "* T023 - Body Part, Organ, or Organ Component\n",
    "* T061 - Therapeutic or Preventive Procedure \n",
    "* T060 - Diagnostic Procedure\n",
    "* T059 - Laboratory Procedure\n",
    "* T034 - Laboratory or Test Result \n",
    "* T184 - Sign or Symptom \n",
    "* T200 - Clinical Drug\n",
    "\n",
    "We'll store this info into a dictionary now.\n",
    "\n",
    "<!-- Some useful def's \n",
    "Finding - \n",
    "That which is discovered by direct observation or measurement of an organism attribute or condition, including the clinical history of the patient. The history of the presence of a disease is a 'Finding' and is distinguished from the disease itself.  -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "648a82cd-17ce-4623-aa5b-3927a2792a9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'T047': 'Disease or Syndrome',\n",
       " 'T121': 'Pharmacologic Substance',\n",
       " 'T023': 'Body Part, Organ, or Organ Component',\n",
       " 'T061': 'Therapeutic or Preventive Procedure',\n",
       " 'T060': 'Diagnostic Procedure',\n",
       " 'T059': 'Laboratory Procedure',\n",
       " 'T034': 'Laboratory or Test Result',\n",
       " 'T184': 'Sign or Symptom',\n",
       " 'T200': 'Clinical Drug'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SEMANTIC_TYPES = ['T047', 'T121', 'T023', 'T061', 'T060', 'T059', 'T034', 'T184', 'T200']\n",
    "SEMANTIC_NAMES = ['Disease or Syndrome', 'Pharmacologic Substance', 'Body Part, Organ, or Organ Component', \\\n",
    "                  'Therapeutic or Preventive Procedure', 'Diagnostic Procedure', 'Laboratory Procedure', \\\n",
    "                  'Laboratory or Test Result', 'Sign or Symptom', 'Clinical Drug']\n",
    "SEMANTIC_TYPE_TO_NAME = dict(zip(SEMANTIC_TYPES, SEMANTIC_NAMES))\n",
    "\n",
    "SEMANTIC_TYPE_TO_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "31d7893c-015f-45bc-914f-3656f1047dae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'diagnosis': {'T047', 'T060'},\n",
       " 'med_history_symptom': {'T184'},\n",
       " 'med_history_operation': {'T061'},\n",
       " 'med_history_other': {'T023',\n",
       "  'T034',\n",
       "  'T047',\n",
       "  'T059',\n",
       "  'T060',\n",
       "  'T061',\n",
       "  'T121',\n",
       "  'T184',\n",
       "  'T200'},\n",
       " 'med_allergy': {'T121', 'T200'},\n",
       " 'test_results': {'T034', 'T059'}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CONFLICT_TO_SEMANTIC_TYPE = {\n",
    "    \"diagnosis\": {'T047', 'T060'},\n",
    "    \"med_history_symptom\": {'T184'},\n",
    "    \"med_history_operation\": {'T061'},\n",
    "    \"med_history_other\": set(SEMANTIC_TYPES),\n",
    "    \"med_allergy\": {'T200', 'T121'},\n",
    "    \"test_results\": {'T059', 'T034'}\n",
    "}\n",
    "\n",
    "CONFLICT_TO_SEMANTIC_TYPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "25d63e0c-7683-44e4-902f-5bbb25918126",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_structures import Patient,\\\n",
    "                            Note, PrescriptionOrders, LabResults,\\\n",
    "                            Sentence, Prescription, Lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2d50ab5f-1ab7-4cc2-854d-9b0e126a4805",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from importlib import reload # python 2.7 does not require this\n",
    "# import data_structures\n",
    "# reload(data_structures)\n",
    "# from data_structures import Patient,\\\n",
    "#                             Note, PrescriptionOrders, LabResults,\\\n",
    "#                             Sentence, Prescription, Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73bb66b-996b-41dd-83db-980cc2d16470",
   "metadata": {},
   "source": [
    "# 3. Load and process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fa00ab4c-6120-46bf-9bf5-d98813294c4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/opennotes/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3166: DtypeWarning: Columns (4,5) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "/opt/conda/envs/opennotes/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3166: DtypeWarning: Columns (11) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "# Load MIMIC tables\n",
    "notes_df  = pd.read_csv('NOTEEVENTS.csv.gz',    compression='gzip', error_bad_lines=False)\n",
    "drug_df   = pd.read_csv('PRESCRIPTIONS.csv.gz', compression='gzip', error_bad_lines=False)\n",
    "lab_df    = pd.read_csv('LABEVENTS.csv.gz',     compression='gzip', error_bad_lines=False)\n",
    "d_lab_df  = pd.read_csv('D_LABITEMS.csv.gz',    compression='gzip', error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "024b290a-397f-469b-bdfb-7cce83b46255",
   "metadata": {},
   "source": [
    "#### Updated script for processing HADM ID's with consecutive physician notes (does not count the autosaves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0f2cad93-04cb-44d4-9720-50c83435590e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 8158 patients with consecutive physician notes.\n"
     ]
    }
   ],
   "source": [
    "# Load HADM ID's with consecutive physician notes\n",
    "if os.path.exists(\"hadm_ids.pkl\"):\n",
    "    with open(\"hadm_ids.pkl\", \"rb\") as f:\n",
    "        hadm_ids = pickle.load(f)\n",
    "else:\n",
    "    hadm_ids = []\n",
    "    for hadm_id in tqdm(notes_df.HADM_ID.unique()):\n",
    "        hadm_data = notes_df.loc[notes_df.HADM_ID == hadm_id]\n",
    "        hadm_phys_notes = hadm_data.loc[hadm_data.CATEGORY == \"Physician \"]\n",
    "\n",
    "        if len(hadm_phys_notes.CHARTTIME.unique()) > 1: # ensure > 1 unique notes (not counting autosave)\n",
    "            hadm_ids.append(hadm_id)\n",
    "\n",
    "    with open(\"hadm_ids.pkl\", \"wb\") as f:\n",
    "        pickle.dump(hadm_ids, f)\n",
    "        \n",
    "print(f\"There are {len(hadm_ids)} patients with consecutive physician notes.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d822e16-d304-42d7-9738-541803177e1a",
   "metadata": {},
   "source": [
    "# 4. Defining Pair Generation Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d9b47fd1-91b9-4753-81cc-d11a4e76cfe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_comparable_type(data_i, data_j):\n",
    "    \"\"\" We only want to compare note-to-note OR note-to-structured data. \n",
    "    \n",
    "    Comparable types:\n",
    "    - sentence v. sentence\n",
    "    - sentence v. prescription\n",
    "    - sentence v. lab\n",
    "    \n",
    "    Uncomparable types:\n",
    "    - lab v. lab \n",
    "    - lab v. prescription\n",
    "    - prescription v. prescription\n",
    "    \"\"\"\n",
    "    return (data_i.type == \"sentence\"     and data_j.type == \"sentence\") or \\\n",
    "           (data_i.type == \"sentence\"     and data_j.type == \"prescription\") or \\\n",
    "           (data_i.type == \"prescription\" and data_j.type == \"sentence\") or \\\n",
    "           (data_i.type == \"sentence\"     and data_j.type == \"lab\") or \\\n",
    "           (data_i.type == \"lab\"          and data_j.type == \"sentence\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5b898008-e394-4cf5-a833-ade056d5cb22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def generate_data_pairs(pat):\n",
    "    processed_pairs = []  # for dataframe + csv\n",
    "    data_inst_pairs = []  # for pipeline, list of tuples: ((Data 1, Data 2), label)\n",
    "    pair_idx = 0\n",
    "\n",
    "    # Iterate over all of the patient's DailyData instances (e.g. note, prescription order, lab results for same day)\n",
    "    ## pat.dailydata = {[date]: [DailyData instance from that date], ...}\n",
    "    for day, pat_dailydatas in pat.dailydata.items(): # pat_dailydatas is list of all DailyData instances for `day`\n",
    "        print(f\"********** Processing data for {day} **********\")\n",
    "        # Collect all the daily datas (note, prescription orders, lab results) for current day\n",
    "        current_dds = []\n",
    "        current_dds_features = []\n",
    "        current_dds_txts = []\n",
    "        current_dds_sem_types = []\n",
    "        current_dds_sem_names = []\n",
    "        for dd in pat_dailydatas: # iterating over DailyData instances, e.g. dd=physician note taken on `day`\n",
    "            current_dds.extend(dd.datas)\n",
    "            current_dds_features.extend(dd.datas_features)\n",
    "            current_dds_txts.extend(dd.datas_txts)\n",
    "            current_dds_sem_types.extend(dd.datas_semantic_types)\n",
    "            current_dds_sem_names.extend(dd.datas_semantic_names)\n",
    "\n",
    "        current_dds           = np.array(current_dds)\n",
    "        current_dds_features  = np.array(current_dds_features)\n",
    "        current_dds_txts      = np.array(current_dds_txts)\n",
    "        current_dds_sem_types = np.array(current_dds_sem_types)\n",
    "        current_dds_sem_names = np.array(current_dds_sem_names)\n",
    "\n",
    "        # extract similar sentences for each semantic type\n",
    "        for sem_type in SEMANTIC_TYPES:\n",
    "            # data for this semantic type\n",
    "            sem_type_bools   = [sem_type in x for x in current_dds_sem_types]\n",
    "            sem_type_indices = np.where(sem_type_bools)[0]\n",
    "            indices_map = dict(\n",
    "                            zip(range(len(sem_type_indices)), \n",
    "                                sem_type_indices)\n",
    "                          )  # maps regular indices in sem_type_current_dds_* lists to indices in current_dds_* lists\n",
    "\n",
    "            sem_type_current_dds           = current_dds[sem_type_indices]\n",
    "            sem_type_current_dds_features  = current_dds_features[sem_type_indices]\n",
    "            sem_type_current_dds_txts      = current_dds_txts[sem_type_indices]\n",
    "            sem_type_current_dds_sem_types = current_dds_sem_types[sem_type_indices]\n",
    "            sem_type_current_dds_sem_names = current_dds_sem_names[sem_type_indices]\n",
    "\n",
    "            # current_dds_featuresfor features (umls + rxnorm concepts)\n",
    "            vectorizer = CountVectorizer()\n",
    "            corpus = list(map(lambda x: ' '.join(x), sem_type_current_dds_features))\n",
    "            if len(corpus) == 0: # skip rest if no candidate sentences exist\n",
    "                continue\n",
    "            X = vectorizer.fit_transform(corpus)\n",
    "            X = X.toarray()\n",
    "\n",
    "            # get cosine similarity using umls + rxnorm concepts\n",
    "            similarity = cosine_similarity(X)     # larger=more similar\n",
    "            sim_is, sim_js = np.where(similarity>0.5) # all pairs with at least 0.5 similarity\n",
    "\n",
    "            for i, j in zip(sim_is, sim_js):\n",
    "                data_i = sem_type_current_dds[i]\n",
    "                data_j = sem_type_current_dds[j]\n",
    "                # removing same sentence pairs, checking dates\n",
    "                if i>j and is_comparable_type(data_i, data_j):\n",
    "                    print(f\"***** PAIR INDEX {pair_idx} *****\")\n",
    "                    print(f\"Cosine similarity: {similarity[i, j]}\")\n",
    "                    print(f\"----- Data i -----\")\n",
    "                    print(f\">> Time: {data_i.time}\\n\" +\\\n",
    "                          f\">> Type: {data_i.type}\\n\" +\\\n",
    "                          f\">> Concepts: {data_i.features}\\n\" +\\\n",
    "                          f\">> {data_i.txt}\")\n",
    "                    print(f\"----- Data j -----\")\n",
    "                    print(f\">> Time: {data_j.time}\\n\" +\\\n",
    "                          f\">> Type: {data_j.type}\\n\" +\\\n",
    "                          f\">> Concepts: {data_j.features}\\n\" +\\\n",
    "                          f\">> {data_j.txt}\")\n",
    "                    print(\"**********************************\")\n",
    "\n",
    "                    # save\n",
    "                    processed_pairs.append([data_i.txt,      data_j.txt, \\\n",
    "                                            data_i.time,     data_j.time, \\\n",
    "                                            data_i.type,     data_j.type, \\\n",
    "                                            data_i.features, data_j.features, \\\n",
    "                                            similarity[i, j], SEMANTIC_TYPE_TO_NAME[sem_type]])\n",
    "            #                                 SEMANTIC_TYPE_TO_NAME[semantic_type]])\n",
    "\n",
    "                    data_inst_pairs.append(((data_i, data_j), None))\n",
    "                    pair_idx += 1\n",
    "\n",
    "    ###############\n",
    "    #### Final ####\n",
    "    ###############        \n",
    "    df = \\\n",
    "    pd.DataFrame(np.array(processed_pairs), \\\n",
    "                 columns=[\"sentence 1\", \"sentence 2\", \\\n",
    "                          \"time 1\", \"time 2\", \\\n",
    "                          \"type 1\", \"type 2\", \\\n",
    "                          \"concepts 1\", \"concepts 2\", \\\n",
    "                          \"cosine similarity\", \"semantic type\"])\n",
    "    \n",
    "    return df, data_inst_pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd90543-196e-4f15-a1e3-c085d33e1e5a",
   "metadata": {},
   "source": [
    "# 5. Defining Feature Generation Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "659f2df4-dcdd-4361-9cc6-03e369741cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_diagnosis = lambda stype: stype in CONFLICT_TO_SEMANTIC_TYPE['diagnosis']\n",
    "is_med       = lambda stype: stype in CONFLICT_TO_SEMANTIC_TYPE['med_allergy']\n",
    "is_test      = lambda stype: stype in CONFLICT_TO_SEMANTIC_TYPE['test_results']\n",
    "\n",
    "def get_conflict_type(s1, s2):\n",
    "    conflict_types = []\n",
    "    \n",
    "    is_diag_s1 = any([is_diagnosis(stype) for stype in s1.semantic_types])\n",
    "    is_diag_s2 = any([is_diagnosis(stype) for stype in s2.semantic_types])\n",
    "    if is_diag_s1 and is_diag_s2: conflict_types.append(\"diagnosis\")\n",
    "\n",
    "    is_med_s1 = any([is_med(stype) for stype in s1.semantic_types])\n",
    "    is_med_s2 = any([is_med(stype) for stype in s2.semantic_types])\n",
    "    if is_med_s1 and is_med_s2: conflict_types.append(\"med\")\n",
    "\n",
    "    is_test_s1 = any([is_test(stype) for stype in s1.semantic_types])\n",
    "    is_test_s2 = any([is_test(stype) for stype in s2.semantic_types])\n",
    "    if is_test_s1 and is_test_s2: conflict_types.append(\"test\")\n",
    "        \n",
    "    return conflict_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ad84f68d-12e1-4f0a-ad6c-cdb620fd84b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if number of neg tokens is equal, return 0; otherwise, return 1\n",
    "def check_if_number_neg_equal_umls(s1, s2):\n",
    "    sent_doc_1_umls = s1.umls_doc    # \"Doc\" output for UMLS \n",
    "    sent_doc_2_umls = s2.umls_doc    # \"Doc\" output for UMLS\n",
    "    \n",
    "    negation_tokens_1 = [tok for tok in sent_doc_1_umls if tok.dep_ == 'neg']\n",
    "    negation_tokens_2 = [tok for tok in sent_doc_2_umls if tok.dep_ == 'neg']\n",
    "\n",
    "    if len(negation_tokens_1) != len(negation_tokens_2):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "588023c7-949c-4d3b-8986-72b168fabe5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Get dependency tokens based on UMLS ontology\n",
    "\"\"\"\n",
    "def create_dep_encoding(s1, s2):\n",
    "\n",
    "    sent_doc_1 = s1.umls_doc\n",
    "    sent_doc_2 = s2.umls_doc\n",
    "\n",
    "    dep_child_1 = []\n",
    "    dep_child_2 = []\n",
    "\n",
    "    for token in sent_doc_1:\n",
    "        if token.dep_ == \"ROOT\": \n",
    "            index_to_check = token.i\n",
    "            dep_list_1 = [token.text for token in sent_doc_1[index_to_check].children if token.dep_ != \"punct\"]\n",
    "            dep_child_1.append(sent_doc_1[index_to_check].text)\n",
    "            dep_child_1.extend(dep_list_1)\n",
    "\n",
    "    for token in sent_doc_2:\n",
    "        if token.dep_ == \"ROOT\":\n",
    "            index_to_check = token.i\n",
    "            dep_list_2 = [token.text for token in sent_doc_2[index_to_check].children if token.dep_ != \"punct\"]\n",
    "            dep_child_2.append(sent_doc_2[index_to_check].text)\n",
    "            dep_child_2.extend(dep_list_2)\n",
    "\n",
    "    dep_sent_1 = list_to_string(dep_child_1)\n",
    "    dep_sent_2 = list_to_string(dep_child_2)\n",
    "\n",
    "    dep_doc_1 = umls_nlp(dep_sent_1)\n",
    "    dep_doc_2 = umls_nlp(dep_sent_2)\n",
    "    similarity = dep_doc_1.similarity(dep_doc_2)\n",
    "    return similarity\n",
    "\n",
    "def list_to_string(list1):\n",
    "    str1 = \"\"\n",
    "    for element in list1:\n",
    "        str1 += \" \" + element\n",
    "\n",
    "    return str1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0b8444c8-77b1-4b0e-983c-3642dfc71ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Given Sentence instances s1, s2\n",
    "check if they share a shared concept feature (UMLS and RxNorm concepts) \n",
    "if they do not share a concept, return 1; otherwise, return 0\n",
    "\"\"\"\n",
    "def check_shared_feature_umls(s1,s2):\n",
    "    #{'Scanning'}\n",
    "    s1_features = s1.features\n",
    "    s2_features = s2.features\n",
    "    \n",
    "    # check if share feature in common\n",
    "    shared_feature = list(set(s1_features) & set(s2_features))\n",
    "    \n",
    "    # do not share concept\n",
    "    if shared_feature != []:\n",
    "        return 1\n",
    "    else: \n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "794fd532-ed8e-4e7d-ae8c-435f5b5fe394",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Med7 (prescription) entities\n",
    "# if not talking about same DRUG -> return 0\n",
    "# if same DRUG but other info different -> return 1\n",
    "\"\"\"\n",
    "def check_shared_feature_med7(s1,s2):\n",
    "    \n",
    "    # [('2U', 'DOSAGE'), ('PRBC', 'DRUG')]\n",
    "    s1_features = s1.med7_entities\n",
    "    s2_features = s2.med7_entities\n",
    "    \n",
    "    # get drug names for each sentence\n",
    "    s1_names = [name for (name, word_type) in s1_features if word_type == \"DRUG\"]\n",
    "    s2_names = [name for (name, word_type) in s2_features if word_type == \"DRUG\"]\n",
    "    \n",
    "    # check if drug name is in common\n",
    "    shared_drug = list(set(s1_names) & set(s2_names))\n",
    "    \n",
    "    # share drug name, but linkers are different\n",
    "    if shared_drug != [] and s1_features != s2_features:\n",
    "        return 1\n",
    "    else: \n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aee3a2a4-161d-4f76-840b-858e85641194",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Use above methods to get features for data\n",
    "s1, s2 are Sentence instances\n",
    "\"\"\"\n",
    "def get_feature_df_mimic(s1, s2, hadm_id, pair_id):\n",
    "    sentence_1 = s1.txt\n",
    "    sentence_2 = s2.txt\n",
    "    \n",
    "    # check negation in docs\n",
    "    neg_check_umls = check_if_number_neg_equal_umls(s1, s2)\n",
    "\n",
    "    # check shared features in UMLS and Med7\n",
    "    check_umls = check_shared_feature_umls(s1,s2)\n",
    "    check_med7 = check_shared_feature_med7(s1,s2)\n",
    "    \n",
    "    # find dependent children similarity\n",
    "    dep_similarity = create_dep_encoding(s1, s2)\n",
    "    \n",
    "    # get conflict type -- returns list \n",
    "    conflict_type = get_conflict_type(s1, s2)\n",
    "    \n",
    "    sentence_info = [neg_check_umls, check_umls, check_med7, \\\n",
    "                     sentence_1, sentence_2, dep_similarity, \\\n",
    "                     hadm_id, conflict_type, pair_id]\n",
    "    \n",
    "    return sentence_info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc39415e-3868-4c41-bb29-97cf87f5c05b",
   "metadata": {},
   "source": [
    "# 6. Predicting Contradiction for Anvil"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a88e081-dd49-40c7-ad3c-51096c42225c",
   "metadata": {},
   "source": [
    "## Load Hybrid Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "359684d6-7244-4947-8c27-e089ac802b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Tuple\n",
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "class RuleAugmentedEstimator(BaseEstimator):\n",
    "  \"\"\"\n",
    "  Augments sklearn estimators with deterministic rule-based logic.\n",
    "  \"\"\"\n",
    "\n",
    "  def __init__(self, base_model: BaseEstimator, rules: Dict, **base_params):\n",
    "      \"\"\"\n",
    "      Initializes the rule-augmented estimator by supplying underlying sklearn estimator\n",
    "      and hard-coded rules.\n",
    "\n",
    "      Args:\n",
    "        base_model: underlying sklearn estimator.\n",
    "          Must implement fit and predict method.\n",
    "        rules: hard coded rules in format of dictionary,\n",
    "          with keys being the pandas dataframe column name, \n",
    "          and values being a tuple in the following form: \n",
    "          (comparison operator, value, return value)\n",
    "\n",
    "          Acceptable comparison operators are: \n",
    "          \"=\", \"<\", \">\", \"<=\", \">=\"\n",
    "\n",
    "          Example:\n",
    "                \n",
    "                {\"House Type\": [\n",
    "                    (\"=\", \"Penthouse\", 1.0),\n",
    "                    (\"=\", \"Shack\", 0.0)\n",
    "                  ],\n",
    "                  \"House Price\": [\n",
    "                      (\"<\", 1000.0, 0.0),\n",
    "                      (\">=\", 500000.0, 1.0)\n",
    "                ]}\n",
    "        **base_params: Optional keyword arguments which will be passed on\n",
    "            to the base_model.\n",
    "\n",
    "      \"\"\"\n",
    "      self.rules = rules\n",
    "      self.base_model = base_model\n",
    "      self.base_model.set_params(**base_params)\n",
    "      self.outcome_range = [0,1]\n",
    "\n",
    "  def __repr__(self):\n",
    "      return \"Rule Augmented Estimator:\\n\\n\\t Base Model: {}\\n\\t Rules: {}\".format(self.base_model, self.rules)\n",
    "\n",
    "  def __str__(self):\n",
    "      return self.__str__\n",
    "\n",
    "  def _get_base_model_data(self, X: pd.DataFrame, y: pd.Series) -> Tuple[pd.DataFrame, pd.Series]:\n",
    "      \"\"\"\n",
    "      Filters the training data for data points not affected by the rules.\n",
    "      \"\"\"\n",
    "      train_x = X\n",
    "\n",
    "      for category, rules in self.rules.items():\n",
    "\n",
    "          if category not in train_x.columns.values: continue\n",
    "\n",
    "          for rule in rules:\n",
    "\n",
    "              if rule[0] == \"=\":\n",
    "                  train_x = train_x.loc[train_x[category] != rule[1]]\n",
    "\n",
    "              elif rule[0] == \"<\":\n",
    "                  train_x = train_x.loc[train_x[category] >= rule[1]]\n",
    "\n",
    "              elif rule[0] == \">\":\n",
    "                  train_x = train_x.loc[train_x[category] <= rule[1]]\n",
    "\n",
    "              elif rule[0] == \"<=\":\n",
    "                  train_x = train_x.loc[train_x[category] > rule[1]]\n",
    "\n",
    "              elif rule[0] == \">=\":\n",
    "                  train_x = train_x.loc[train_x[category] < rule[1]]\n",
    "\n",
    "              else:\n",
    "                  print(\"Invalid rule detected: {}\".format(rule))\n",
    "              \n",
    "      indices = train_x.index.values\n",
    "      train_y = y.iloc[indices]\n",
    "      \n",
    "      train_x = train_x.reset_index(drop=True)\n",
    "      train_y = train_y.reset_index(drop=True)\n",
    "      \n",
    "      return train_x, train_y   \n",
    "\n",
    "  def fit(self, X: pd.DataFrame, y: pd.Series, **kwargs):\n",
    "      \"\"\"Fits the estimator to the data.\n",
    "      \n",
    "      Fits the estimator to the data, only training the underlying estimator\n",
    "      on data which isn't affected by the hard-coded rules.\n",
    "      \n",
    "      Args:\n",
    "          X: The training feature data.\n",
    "          y: The training label data.\n",
    "          **kwargs: Optional keyword arguments passed to the underlying\n",
    "          estimator's fit function.\n",
    "              \n",
    "      \"\"\"\n",
    "      train_x, train_y = self._get_base_model_data(X, y)\n",
    "      self.base_model.fit(train_x, train_y, **kwargs)\n",
    "\n",
    "  def predict(self, X: pd.DataFrame) -> np.array:\n",
    "      \"\"\"Gets predictions for the provided feature data.\n",
    "      \n",
    "      The predicitons are evaluated using the provided rules wherever possible\n",
    "      otherwise the underlying estimator is used.\n",
    "      \n",
    "      Args:\n",
    "          X: The feature data to evaluate predictions for.\n",
    "      \n",
    "      Returns:\n",
    "          np.array: Evaluated predictions.\n",
    "      \"\"\"\n",
    "      \n",
    "      p_X = X.copy()\n",
    "      p_X['prediction'] = np.nan\n",
    "\n",
    "      for category, rules in self.rules.items():\n",
    "\n",
    "          if category not in p_X.columns.values: continue\n",
    "\n",
    "          for rule in rules:\n",
    "\n",
    "              if rule[0] == \"=\":\n",
    "                  p_X.loc[p_X[category] == rule[1], 'prediction'] = rule[2]\n",
    "\n",
    "              elif rule[0] == \"<\":\n",
    "                  p_X.loc[p_X[category] < rule[1], 'prediction'] = rule[2]\n",
    "\n",
    "              elif rule[0] == \">\":\n",
    "                  p_X.loc[p_X[category] > rule[1], 'prediction'] = rule[2]\n",
    "\n",
    "              elif rule[0] == \"<=\":\n",
    "                  p_X.loc[p_X[category] <= rule[1], 'prediction'] = rule[2]\n",
    "\n",
    "              elif rule[0] == \">=\":\n",
    "                  p_X.loc[p_X[category] >= rule[1], 'prediction'] = rule[2]\n",
    "\n",
    "              else:\n",
    "                  print(\"Invalid rule detected: {}\".format(rule))\n",
    "\n",
    "      if len(p_X.loc[p_X['prediction'].isna()].index != 0):\n",
    "\n",
    "          base_X = p_X.loc[p_X['prediction'].isna()].copy()\n",
    "          base_X.drop('prediction', axis=1, inplace=True)\n",
    "          p_X.loc[p_X['prediction'].isna(), 'prediction'] = self.base_model.predict(base_X)\n",
    "\n",
    "      return p_X['prediction'].values\n",
    "    \n",
    "  def get_params(self, deep: bool = True) -> Dict:\n",
    "      \"\"\"Return the model's and base model's parameters.\n",
    "      Args:\n",
    "          deep: Whether to recursively return the base model's parameters.\n",
    "      Returns\n",
    "          Dict: The model's parameters.\n",
    "      \"\"\"\n",
    "      \n",
    "      params = {'base_model': self.base_model,\n",
    "                'outcome_range': self.outcome_range,\n",
    "                'rules': self.rules\n",
    "                }\n",
    "\n",
    "      params.update(self.base_model.get_params(deep=deep))\n",
    "      return params\n",
    "    \n",
    "  def set_params(self, **params):\n",
    "      \"\"\"Sets parameters for the model and base model.\n",
    "      Args:\n",
    "          **params: Optional keyword arguments.\n",
    "      \"\"\"\n",
    "                \n",
    "      parameters = params\n",
    "      param_keys = parameters.keys()\n",
    "      \n",
    "      if 'base_model' in param_keys:\n",
    "          value = parameters.pop('base_model')\n",
    "          self.base_model = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8a56b88e-ec39-44ac-aa2e-1c62f0911a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Code \"\"\"\n",
    "def get_start_end(data, full_dd):\n",
    "    # Get approximate index for sentence\n",
    "    approx_idx = None\n",
    "    words = data.split(\" \")\n",
    "    for w in words:\n",
    "        if len(w) > 0:  \n",
    "            try: \n",
    "                fwd_idx = full_dd.find(w)\n",
    "                rev_idx = full_dd.rfind(w)\n",
    "                if fwd_idx == rev_idx:\n",
    "                    approx_idx = fwd_idx\n",
    "                    break\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "    approx_lower = (approx_idx - len(data))\n",
    "    approx_upper = (approx_idx + len(data))\n",
    "\n",
    "    # find starting and end indices\n",
    "    i=0\n",
    "    while full_dd[approx_lower:approx_upper].find(words[i]) == -1:\n",
    "            i+=1\n",
    "\n",
    "    start = full_dd[approx_lower:approx_upper].find(words[i])\n",
    "    if start == -1: \n",
    "        raise Exception\n",
    "    start += approx_lower\n",
    "\n",
    "    i=len(words)-1\n",
    "    while full_dd[approx_lower:approx_upper].rfind(words[i]) == -1:\n",
    "            i-=1\n",
    "\n",
    "    end = full_dd[approx_lower:approx_upper].rfind(words[i])\n",
    "    if end == -1: \n",
    "        raise Exception\n",
    "    end += approx_lower\n",
    "    end += len(words[i])\n",
    "    \n",
    "#     print(f\"Data: {data}\")\n",
    "#     print(f\"Daily Data: {full_dd[start:end]}\")\n",
    "    \n",
    "    return start, end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d79bd1ac-08b6-4eee-8275-ffb660b9d039",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/opennotes/lib/python3.7/site-packages/sklearn/base.py:315: UserWarning: Trying to unpickle estimator DummyClassifier from version 0.22.2.post1 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/envs/opennotes/lib/python3.7/site-packages/sklearn/base.py:315: UserWarning: Trying to unpickle estimator DecisionTreeRegressor from version 0.22.2.post1 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/envs/opennotes/lib/python3.7/site-packages/sklearn/base.py:315: UserWarning: Trying to unpickle estimator GradientBoostingClassifier from version 0.22.2.post1 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "with open(\"hybrid_model_gen_train.pkl\", \"rb\") as f:\n",
    "    model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4c25a688-aca9-4aa3-bdd3-9c7faad8efd7",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: anvil-uplink in /opt/conda/envs/opennotes/lib/python3.7/site-packages (0.3.36)\n",
      "Collecting argparse\n",
      "  Using cached argparse-1.4.0-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: six in /opt/conda/envs/opennotes/lib/python3.7/site-packages (from anvil-uplink) (1.15.0)\n",
      "Requirement already satisfied: ws4py in /opt/conda/envs/opennotes/lib/python3.7/site-packages (from anvil-uplink) (0.5.1)\n",
      "Requirement already satisfied: future in /opt/conda/envs/opennotes/lib/python3.7/site-packages (from anvil-uplink) (0.18.2)\n",
      "Installing collected packages: argparse\n",
      "Successfully installed argparse-1.4.0\n",
      "Disconnecting from previous connection first...\n",
      "Connecting to wss://anvil.works/uplink\n",
      "Anvil websocket closed (code 1000, reason=b'')\n",
      "Anvil websocket open\n",
      "Connected to \"Default environment (dev)\" as SERVER\n"
     ]
    }
   ],
   "source": [
    "!pip install anvil-uplink \n",
    "import anvil.server\n",
    "anvil.server.connect(\"MOTXDGUEXATA45F7IWO43RPN-ZY7LJ3KQDIXNU7FW\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "85fa54c4-4e78-481a-88c0-3868cdd6a967",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[155131.0,\n",
       " 129414.0,\n",
       " 133623.0,\n",
       " 197325.0,\n",
       " 186291.0,\n",
       " 180836.0,\n",
       " 154802.0,\n",
       " 133857.0,\n",
       " 166389.0,\n",
       " 196357.0]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hadm_ids[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d740afe1-8df8-4d4f-826f-8cd04dc349f8",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def _get_contradictions(hadm_id): \n",
    "    # Step 1: Process data for patient\n",
    "    print(f\"Processing patient {int(hadm_id)} data...\")\n",
    "    pat = Patient(hadm_id, notes_df, drug_df, lab_df, d_lab_df, \\\n",
    "                  med7_nlp, umls_nlp, rxnorm_nlp, umls_linker, rxnorm_linker, \\\n",
    "                  physician_only=True)\n",
    "\n",
    "    # Step 2: Generate pairs for this patient\n",
    "    print(f\"Generating candidate data pairs...\")\n",
    "    df, data_inst_pairs = generate_data_pairs(pat)\n",
    "\n",
    "    # Step 3: Building feature set for pairs\n",
    "    total_features = []\n",
    "    for pair_id in tqdm(range(len(data_inst_pairs))):\n",
    "        (s1, s2), _ = data_inst_pairs[pair_id]\n",
    "        features = get_feature_df_mimic(s1, s2, hadm_id, pair_id)\n",
    "        total_features.append(features)\n",
    "\n",
    "    cols = \\\n",
    "    [\"neg_check_umls\", \"check_umls\", \"check_med7\", \\\n",
    "         \"sentence_1\", \"sentence_2\", \"dep_sim\", \\\n",
    "         \"hadm_id\", \"conflict_type\", \"pair_id\"]\n",
    "    mimic_total_features_df = pd.DataFrame(total_features, columns=cols)\n",
    "\n",
    "    # Step 4: Predicting contradictions\n",
    "    mimic_X = mimic_total_features_df[['check_umls', 'neg_check_umls', \"check_med7\", \"dep_sim\"]]\n",
    "    predicted_contradiction = model.predict(mimic_X)\n",
    "    \n",
    "    # Step 5: Building contradiction dictionary for Anvil\n",
    "    #         Dictionary, {“lab”: (contradiction 1, contradiction 2, …), “prescription”: …} \n",
    "    #         contradiction i = (sentence 1, sentence 2, conflict type, \n",
    "    #                            data type 1, data type 2, full note 1, full note 2, \n",
    "    #                            time 1, time 2,\n",
    "    #                            start index 1, end index 1, start index 2, end index 2, same note?) \n",
    "    # Iterate over the data pairs and add to output\n",
    "    output = {\"diagnosis\": [], \"prescription\": [], \"lab\": []}\n",
    "\n",
    "    for i in tqdm(range(len(data_inst_pairs))):\n",
    "        (s1, s2), _ = data_inst_pairs[i]\n",
    "\n",
    "        feats = mimic_total_features_df.iloc[i]\n",
    "        label = predicted_contradiction[i]\n",
    "\n",
    "        if label != 1: # skip anything not a contradiction\n",
    "            continue\n",
    "\n",
    "        is_same_dd = (s1.dailydata == s2.dailydata)\n",
    "        time1 = s1.dailydata.time.strftime(\"%m/%d/%Y, %H:%M:%S\")\n",
    "        time2 = s2.dailydata.time.strftime(\"%m/%d/%Y, %H:%M:%S\")\n",
    "\n",
    "        # get start and end indices for sentences\n",
    "        # if fail, continue\n",
    "        if s1.type == \"sentence\":\n",
    "            try: # try getting start and end indices\n",
    "                start1, end1 = get_start_end(s1.txt, s1.dailydata.txt)\n",
    "            except Exception:\n",
    "                continue\n",
    "        else:\n",
    "            start1, end1 = None, None\n",
    "\n",
    "        if s2.type == \"sentence\":\n",
    "            try: # try getting start and end indices\n",
    "                start2, end2 = get_start_end(s2.txt, s2.dailydata.txt)\n",
    "            except Exception:\n",
    "                continue\n",
    "        else:\n",
    "            start2, end2 = None, None\n",
    "\n",
    "    #         contradiction_info = (\n",
    "    #             s1.txt, s2.txt, feats.conflict_type, \\\n",
    "    #             s1.type, s2.type, s1.dailydata.txt, s2.dailydata.txt, \\\n",
    "    #             time1, time2, \\\n",
    "    #             start1, end1, start2, end2, is_same_dd\n",
    "    #         )\n",
    "        if s1.type == \"sentence\": s1_dd = s1.dailydata.txt\n",
    "        else:                     s1_dd = None\n",
    "        if s2.type == \"sentence\": s2_dd = s2.dailydata.txt\n",
    "        else:                     s2_dd = None\n",
    "\n",
    "        if \"med\" in feats.conflict_type: \n",
    "            contradiction_info = (\n",
    "                s1.txt, s2.txt, \"prescription\", \\\n",
    "                s1.type, s2.type, s1_dd, s2_dd, \\\n",
    "                time1, time2, \\\n",
    "                start1, end1, start2, end2, is_same_dd\n",
    "            )\n",
    "            output[\"prescription\"].append(contradiction_info)\n",
    "            print(\"Adding prescription\")\n",
    "        elif \"test\" in feats.conflict_type:\n",
    "            contradiction_info = (\n",
    "                s1.txt, s2.txt, \"lab\", \\\n",
    "                s1.type, s2.type, s1_dd, s2_dd, \\\n",
    "                time1, time2, \\\n",
    "                start1, end1, start2, end2, is_same_dd\n",
    "            )\n",
    "            output[\"lab\"].append(contradiction_info)\n",
    "            print(\"Adding lab\")\n",
    "        elif \"diagnosis\" in feats.conflict_type:\n",
    "            contradiction_info = (\n",
    "                s1.txt, s2.txt, \"diagnosis\", \\\n",
    "                s1.type, s2.type, s1_dd, s2_dd, \\\n",
    "                time1, time2, \\\n",
    "                start1, end1, start2, end2, is_same_dd\n",
    "            )\n",
    "            output[\"diagnosis\"].append(contradiction_info)\n",
    "            print(\"Adding diagnosis\")\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cdb634be-ab6c-4772-b563-3ab80c2a020c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Caching some outputs for speed\n",
    "# for hadm_id in hadm_ids[10:20]:\n",
    "#     output = get_contradictions(hadm_id)\n",
    "#     with open(f\"{int(hadm_id)}.pkl\", \"wb\") as f:\n",
    "#         pickle.dump(output, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "20b2616b-9b78-42fb-977a-4832e4473560",
   "metadata": {},
   "outputs": [],
   "source": [
    "import anvil.server\n",
    "anvil.server.connect(\"MOTXDGUEXATA45F7IWO43RPN-ZY7LJ3KQDIXNU7FW\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf96ec25-1d8c-42a4-873f-d2f5f062bef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "@anvil.server.callable \n",
    "def get_contradictions(hadm_id):\n",
    "    try:\n",
    "        with open(f\"{hadm_id}.pkl\", \"rb\") as f:\n",
    "            output = pickle.load(f)\n",
    "    except:\n",
    "        output = _get_contradictions(hadm_id)\n",
    "        \n",
    "    return output\n",
    "\n",
    "anvil.server.wait_forever() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3e0249-633b-4cf2-8b6c-031a4d5e66ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03c7dc7-867b-44fd-87a2-b2857b5de4d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3bcc42a7-c6d6-4386-8b5d-71119fc14201",
   "metadata": {},
   "source": [
    "# OTHER: Getting History + Allergy Information - @Sharon, you can ignore everytihng below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2c644e-d063-4e7b-b2f8-aff9b2b4e13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo: \n",
    "# - DONE function to re-process all data from Patient instance -- pat.process_notes(); pat.process_by_date()\n",
    "# - function to update Note -- should update dataframe of patient directly\n",
    "#   - can go back to dataframe, but can't map tokenized sentence to original note in df -- todo\n",
    "#   - function to update tokenized sentence\n",
    "# - later: function to update original dataframe from patient dataframe\n",
    "\n",
    "import re\n",
    "\n",
    "def get_section(regex_dict, txt):\n",
    "    \"\"\" Given a dictionary of start and end regex's for a\n",
    "        particular section, gets the start and endpoint of \n",
    "        section in the text and returns indices. \n",
    "        Returns None if section does not exist.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        start    = re.search(regex_dict[\"start\"], txt).start()\n",
    "        end      = re.search(regex_dict[\"end\"],   txt).start()\n",
    "    except AttributeError:\n",
    "        start, end = None, None\n",
    "    \n",
    "    return start, end\n",
    "\n",
    "note = pat.notes[4]\n",
    "\n",
    "# Sections to store \n",
    "# note: most of these sections have already been removed,\n",
    "#       but if they haven't might have to remove then \n",
    "#       reprocess everything\n",
    "allergy_regex = {\"start\": \"Allergies:\",\n",
    "                 \"end\":   \"Last dose of Antibiotics:\"}\n",
    "history_regex = {\"start\": \"Past medical history:\",\n",
    "                 \"end\":   \"Other:\"}\n",
    "\n",
    "allergy_start, allergy_end = get_section(allergy_regex, note.txt)\n",
    "history_start, history_end = get_section(history_regex, note.txt)\n",
    "\n",
    "pt_allergies = \"\" if allergy_start is None else note.txt[allergy_start:allergy_end]\n",
    "pt_histories = \"\" if history_start is None else note.txt[history_start:history_end]\n",
    "\n",
    "print(\"******** Allergies ********\")\n",
    "print(pt_allergies[:100])\n",
    "print(\"******** Histories ********\")\n",
    "print(pt_histories[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc60d0b-c7ac-4d27-b7e7-e3e74364ac1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932b6cfc-f97a-420e-8595-b968eeb2b1af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00fbb6c9-c30b-4b79-a535-7f95b7206ff7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c65a86-d9b7-4e26-a29b-fdf860d1a4a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf3857b-30b6-4c07-867c-6041a9622c2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c45ea67-a917-4878-aa1e-d86b4c33ee5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715515ef-169b-4d6a-aafe-43ee09fdccae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c391c1-51ca-420c-a693-d746da2adcce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
