{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b1de5c-9f12-45cd-88b8-87464b841d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import re\n",
    "import random\n",
    "import pickle\n",
    "import subprocess\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f711066d-fb43-42d7-810d-3624404b69b6",
   "metadata": {},
   "source": [
    "# 1. Setup concept extractors\n",
    "\n",
    "Some options were [MetaMap](https://metamap.nlm.nih.gov/) and [spaCy](https://spacy.io/). \n",
    "\n",
    "[MetaMap](https://metamap.nlm.nih.gov/) is specific to recognizing UMLS concepts. There is a [Python wrapper](https://github.com/AnthonyMRios/pymetamap), but known to be slow and bad.\n",
    "\n",
    "[spaCy](https://spacy.io/) is a popular NLP Python package with an extensive library for named entity recognition. It has a wide variety of [extensions](https://spacy.io/universe) and models to choose from. We're going with the following.\n",
    "\n",
    "* [scispaCy](https://spacy.io/universe/project/scispacy) contains spaCy models for processing biomedical, scientific or clinical text. It seems easy to use and has a wide variety of concepts it can recognize, including UMLS, RxNorm, etc.\n",
    "\n",
    "* [negspaCy](https://spacy.io/universe/project/negspacy) identifies negations using some extension of regEx. Probably useful for things like, \"this pt is diabetic\" v. \"this pt is not diabetic.\" [todo: negation identification of medspacy might be better, https://github.com/medspacy/medspacy]\n",
    "\n",
    "* [Med7](https://github.com/kormilitzin/med7) is a model trained for recognizing entities in prescription text, e.g. identifies drug name, dosage, duration, etc., which could be useful stuff to check for conflicts. \n",
    "\n",
    "We're going with spaCy for this.. and coming up with a coherent way to integrate entities picked up by these three extensions/models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71301789-8d31-49ed-87af-bcb2215da50c",
   "metadata": {},
   "source": [
    "## i) Installations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae2d503-cff3-4fe2-9fbe-e003b28420e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys; sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f9000b-8678-4718-88d4-e41ffefcec41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import scispacy\n",
    "\n",
    "from pprint import pprint\n",
    "from collections import OrderedDict\n",
    "\n",
    "from spacy import displacy\n",
    "# from scispacy.abbreviation import AbbreviationDetector # UMLS already contains abbrev. detect\n",
    "from scispacy.umls_linking import UmlsEntityLinker\n",
    "\n",
    "# should be 2.3.5 and >=0.3.0\n",
    "spacy.__version__, scispacy.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68518fa6-6403-4c67-ae66-0553f50ab89b",
   "metadata": {},
   "source": [
    "## ii) Setting up the model\n",
    "\n",
    "The model is used to form word/sentence embeddings for the NER task. Thus, it's important to choose model that has been tuned for our specific use case (e.g. clinical text, prescription information) so the embeddings are useful for naming the entity.\n",
    "\n",
    "[Note to self:] one potential idea to look into if we have time remaining, something about using custom model for spacy pipeline (could we do smth with the romanov models since they've been trained specifically for conflict detection?) -- https://spacy.io/usage/v3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475a77b2-fee6-456b-8413-c21f8788c584",
   "metadata": {},
   "source": [
    "### a) scispaCy\n",
    "\n",
    "For scispaCy, we set up one of their models that has been trained on biomedical data. Other models can be found [here](https://allenai.github.io/scispacy/). \n",
    "\n",
    "We load two models since we will be linking different entity linkers (knowledge bases that link text to named entites) later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41850bf-6cb2-41f0-a88e-3f0ca7398f3c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "## uncomment to install model if not already installed\n",
    "# !/opt/conda/envs/opennotes/bin/python -m pip install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.2.5/en_core_sci_sm-0.2.5.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb3aa0e-d096-45dc-b3ee-13baf63a3d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for umls (general biomedical concepts)\n",
    "umls_nlp   = spacy.load(\"en_core_sci_sm\")\n",
    "\n",
    "# for rxnorm (prescriptions)\n",
    "rxnorm_nlp = spacy.load(\"en_core_sci_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f8bb022-64b3-4969-b880-6eb717c612a6",
   "metadata": {},
   "source": [
    "### b) Med7\n",
    "\n",
    "For Med7, we set up their model that has been trained specifically for NER of medication-related concepts: dosage, drug names, duration, form, frequency, route of administration, and strength. The model is trained on MIMIC-III, so it should work well for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9672e962-d666-466c-8b5c-4de36d4342f2",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # installs Med7 model\n",
    "# !pip install https://www.dropbox.com/s/xbgsy6tyctvrqz3/en_core_med7_lg.tar.gz?dl=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8786df8a-342d-4f5c-852c-d784902bc321",
   "metadata": {},
   "outputs": [],
   "source": [
    "med7_nlp = spacy.load(\"en_core_med7_lg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "663387a7-1da0-4e39-80e6-534426b6a2f4",
   "metadata": {},
   "source": [
    "## iii) Adding an entity linker\n",
    "\n",
    "The EntityLinker is a spaCy component that links to a knowledge base. The linker compares words with the concepts in the specified knowledge base (e.g. scispaCy's UMLS does some form of character overlap-based nearest neighbor search, has option to resolve abbreviations first).\n",
    "\n",
    "[Note: Entities generally get resolved to a list of different entities. This [blog post](http://sujitpal.blogspot.com/2020/08/disambiguating-scispacy-umls-entities.html) describes one potential way to disambiguate this by figuring out \"most likely\" set of entities. Gonna start off with just resolving to the 1st entity tho... hopefully that's sufficient.]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06cd7515-edfb-4442-885b-f52d0e5d4e27",
   "metadata": {},
   "source": [
    "### a) scispaCy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e405baf0-4cd0-4416-bfd1-17f600be0c93",
   "metadata": {},
   "source": [
    "#### UMLS Linker\n",
    "\n",
    "UMLS linker maps entities to the UMLS concept. Main parts we'll be interested in are: semantic type and concept (mainly the common name, maybe the CUI might become important later).\n",
    "\n",
    "* _Semantic type_ is the broader category that the entity falls under, e.g. disease, pharmacologic substance, etc. See [this](https://metamap.nlm.nih.gov/Docs/SemanticTypes_2018AB.txt) for a full list.\n",
    "\n",
    "* _Concepts_ refer to the more fundamental entity itself, e.g. pneumothorax, ventillator, etc. Many concepts can fall under a semantic type.\n",
    "\n",
    "More info on `UmlsEntityLinker` ([source code](https://github.com/allenai/scispacy/blob/4ade4ec897fa48c2ecf3187caa08a949920d126d/scispacy/linking.py#L9))\n",
    "\n",
    "See source code for `.jsonl` file with the knowledge base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc71654d-e023-42dc-b9e6-9421f40561b0",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from scispacy.umls_linking import UmlsEntityLinker\n",
    "\n",
    "# abbreviation_pipe = AbbreviationDetector(nlp) # automatically included with UMLS linker\n",
    "# nlp.add_pipe(abbreviation_pipe)\n",
    "umls_linker = UmlsEntityLinker(k=10,                          # number of nearest neighbors to look up from\n",
    "                               threshold=0.7,                 # confidence threshold to be added as candidate\n",
    "                               max_entities_per_mention=1,    # number of entities returned per concept (todo: tune)\n",
    "                               filter_for_definitions=False,  # no definition is OK\n",
    "                               resolve_abbreviations=True)    # resolve abbreviations before linking\n",
    "umls_nlp.add_pipe(umls_linker)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa91b326-b714-4698-b21c-0ef098048593",
   "metadata": {},
   "source": [
    "#### RxNorm Linker\n",
    "\n",
    "RxNorm linker maps entities to RxNorm, an ontology for clinical drug names. It contains about 100k concepts for normalized names for clinical drugs. It is comprised of several other drug vocabularies commonly used in pharmacy management and drug interaction, including First Databank, Micromedex, and the Gold Standard Drug Database.\n",
    "\n",
    "More info on `RxNorm` ([NIH page](https://www.nlm.nih.gov/research/umls/rxnorm/index.html), [source code](https://github.com/allenai/scispacy/blob/2290a80cfe0948e48d8ecfbd60064019d57a6874/scispacy/linking_utils.py#L120))\n",
    "\n",
    "See source code for `.jsonl` file with the knowledge base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98a726f-4515-49d0-914c-b8593278a8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scispacy.linking import EntityLinker\n",
    "\n",
    "# rxnorm_linker = EntityLinker(resolve_abbreviations=True, name=\"rxnorm\")\n",
    "rxnorm_linker = EntityLinker(k=10,                          # number of nearest neighbors to look up from\n",
    "                             threshold=0.7,                 # confidence threshold to be added as candidate\n",
    "                             max_entities_per_mention=1,    # number of entities returned per concept (todo: tune)\n",
    "                             filter_for_definitions=False,  # no definition is OK\n",
    "                             resolve_abbreviations=True,    # resolve abbreviations before linking\n",
    "                             name=\"rxnorm\")                 # RxNorm ontology\n",
    "\n",
    "rxnorm_nlp.add_pipe(rxnorm_linker)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5a2032-9dcb-4c1d-ae02-c2785f7b7fca",
   "metadata": {},
   "source": [
    "### b) Med7 \n",
    "\n",
    "No need for entity linker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5697e483-5a37-4431-a57b-96a25a988832",
   "metadata": {},
   "source": [
    "### c) Negspacy [TODO]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f5053d-0f84-476e-b425-9335f2fc6912",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cf6c212a-fc0c-486f-b52c-6193e78842fc",
   "metadata": {},
   "source": [
    "# 2. Setup data structures\n",
    "\n",
    "## Categorizing type of conflict\n",
    "\n",
    "The first larger task is to categorize by the type of conflict to check for since our method will likely be different (at least for the rule based). We wrote up a short list [here](https://docs.google.com/document/d/1fEBk0JHeyQWshYWW5w_VTkaYyRfm9MBxJ9DAGoVa8Yw/edit?usp=sharing). \n",
    "\n",
    "To do this, we're using the semantic type that is identified by the UMLS linker. Here's a table of the semantic types we're filtering for, and which conflict they'll be used for.\n",
    "\n",
    "Here's a [full list](https://metamap.nlm.nih.gov/Docs/SemanticTypes_2018AB.txt) of semantic types. You can look up definitions of semantic types [here](http://linkedlifedata.com/resource/umls-semnetwork/T033).\n",
    "\n",
    "| Conflict | Semantic Type |\n",
    "| --- | ----------- |\n",
    "| Diagnoses-related errors | Disease or Syndrome (T047), Diagnostic Procedure(T060) |\n",
    "| Inaccurate description of medical history (symptoms) | Sign or Symptom (T184) |\n",
    "| Inaccurate description of medical history (operations) | Therapeutic or Preventive Procedure (T061) |\n",
    "| Inaccurate description of medical history (other) | [all of the above and below] |\n",
    "| Medication or allergies | Clinical Drug (T200), Pharmacologic Substance (T121) |\n",
    "| Test procedures or results | Laboratory Procedure (T059), Laboratory or Test Result (T034) | \n",
    "\n",
    "\n",
    "For clarity, the concepts we'll keep from the UMLS linker are anything falling into these semantic types (which we will then categorize by type of conflict using the table above):\n",
    "\n",
    "* T047 - Disease or Syndrome\n",
    "* T121 - Pharmacologic Substance\n",
    "* T023 - Body Part, Organ, or Organ Component\n",
    "* T061 - Therapeutic or Preventive Procedure \n",
    "* T060 - Diagnostic Procedure\n",
    "* T059 - Laboratory Procedure\n",
    "* T034 - Laboratory or Test Result \n",
    "* T184 - Sign or Symptom \n",
    "* T200 - Clinical Drug\n",
    "\n",
    "We'll store this info into a dictionary now.\n",
    "\n",
    "<!-- Some useful def's \n",
    "Finding - \n",
    "That which is discovered by direct observation or measurement of an organism attribute or condition, including the clinical history of the patient. The history of the presence of a disease is a 'Finding' and is distinguished from the disease itself.  -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "648a82cd-17ce-4623-aa5b-3927a2792a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEMANTIC_TYPES = ['T047', 'T121', 'T023', 'T061', 'T060', 'T059', 'T034', 'T184', 'T200']\n",
    "SEMANTIC_NAMES = ['Disease or Syndrome', 'Pharmacologic Substance', 'Body Part, Organ, or Organ Component', \\\n",
    "                  'Therapeutic or Preventive Procedure', 'Diagnostic Procedure', 'Laboratory Procedure', \\\n",
    "                  'Laboratory or Test Result', 'Sign or Symptom', 'Clinical Drug']\n",
    "SEMANTIC_TYPE_TO_NAME = dict(zip(SEMANTIC_TYPES, SEMANTIC_NAMES))\n",
    "\n",
    "SEMANTIC_TYPE_TO_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d7893c-015f-45bc-914f-3656f1047dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFLICT_TO_SEMANTIC_TYPE = {\n",
    "    \"diagnosis\": {'T047', 'T060'},\n",
    "    \"med_history_symptom\": {'T184'},\n",
    "    \"med_history_operation\": {'T061'},\n",
    "    \"med_history_other\": set(SEMANTIC_TYPES),\n",
    "    \"med_allergy\": {'T200', 'T121'},\n",
    "    \"test_results\": {'T059', 'T034'}\n",
    "}\n",
    "\n",
    "CONFLICT_TO_SEMANTIC_TYPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d63e0c-7683-44e4-902f-5bbb25918126",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_structures import Patient,\\\n",
    "                            Note, PrescriptionOrders, LabResults,\\\n",
    "                            Sentence, Prescription, Lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d50ab5f-1ab7-4cc2-854d-9b0e126a4805",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from importlib import reload # python 2.7 does not require this\n",
    "# import data_structures\n",
    "# reload(data_structures)\n",
    "# from data_structures import Patient,\\\n",
    "#                             Note, PrescriptionOrders, LabResults,\\\n",
    "#                             Sentence, Prescription, Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73bb66b-996b-41dd-83db-980cc2d16470",
   "metadata": {},
   "source": [
    "# 3. Load and process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa00ab4c-6120-46bf-9bf5-d98813294c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MIMIC tables\n",
    "notes_df  = pd.read_csv('NOTEEVENTS.csv.gz',    compression='gzip', error_bad_lines=False)\n",
    "drug_df   = pd.read_csv('PRESCRIPTIONS.csv.gz', compression='gzip', error_bad_lines=False)\n",
    "lab_df    = pd.read_csv('LABEVENTS.csv.gz',     compression='gzip', error_bad_lines=False)\n",
    "d_lab_df  = pd.read_csv('D_LABITEMS.csv.gz',    compression='gzip', error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "024b290a-397f-469b-bdfb-7cce83b46255",
   "metadata": {},
   "source": [
    "#### Updated script for processing HADM ID's with consecutive physician notes (does not count the autosaves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2cad93-04cb-44d4-9720-50c83435590e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load HADM ID's with consecutive physician notes\n",
    "if os.path.exists(\"hadm_ids.pkl\"):\n",
    "    with open(\"hadm_ids.pkl\", \"rb\") as f:\n",
    "        hadm_ids = pickle.load(f)\n",
    "else:\n",
    "    hadm_ids = []\n",
    "    for hadm_id in tqdm(notes_df.HADM_ID.unique()):\n",
    "        hadm_data = notes_df.loc[notes_df.HADM_ID == hadm_id]\n",
    "        hadm_phys_notes = hadm_data.loc[hadm_data.CATEGORY == \"Physician \"]\n",
    "\n",
    "        if len(hadm_phys_notes.CHARTTIME.unique()) > 1: # ensure > 1 unique notes (not counting autosave)\n",
    "            hadm_ids.append(hadm_id)\n",
    "\n",
    "    with open(\"hadm_ids.pkl\", \"wb\") as f:\n",
    "        pickle.dump(hadm_ids, f)\n",
    "        \n",
    "print(f\"There are {len(hadm_ids)} patients with consecutive physician notes.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ef6342-07ce-4a65-a944-fbbd85409c7c",
   "metadata": {},
   "source": [
    "# 4. Generating Contradictions\n",
    "\n",
    "Generate 25-50 examples of positive and negative contradictions, each.\n",
    "\n",
    "For lab values: \n",
    "\n",
    "* Find 50-100 total data pairs (about 2-4 per patient) and insert contradiction, or label as not a contradiction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8683c10d-8a01-465f-afbd-e4f44bcf5d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2864ffdc-7fa7-4b0a-91ee-b5349c667efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_colwidth\", -1) # prints full text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3b8a75-05b5-49a4-b944-7231981de0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload # python 2.7 does not require this\n",
    "import data_structures\n",
    "reload(data_structures)\n",
    "from data_structures import Patient,\\\n",
    "                            Note, PrescriptionOrders, LabResults,\\\n",
    "                            Sentence, Prescription, Lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dabcc982-5a88-4324-8377-5d6e5279f877",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_comparable_type(data_i, data_j):\n",
    "    \"\"\" We only want to compare note-to-note OR note-to-structured data. \n",
    "    \n",
    "    Comparable types:\n",
    "    - sentence v. sentence\n",
    "    - sentence v. prescription\n",
    "    - sentence v. lab\n",
    "    \n",
    "    Uncomparable types:\n",
    "    - lab v. lab \n",
    "    - lab v. prescription\n",
    "    - prescription v. prescription\n",
    "    \"\"\"\n",
    "    return (data_i.type == \"sentence\"     and data_j.type == \"sentence\") or \\\n",
    "           (data_i.type == \"sentence\"     and data_j.type == \"prescription\") or \\\n",
    "           (data_i.type == \"prescription\" and data_j.type == \"sentence\") or \\\n",
    "           (data_i.type == \"sentence\"     and data_j.type == \"lab\") or \\\n",
    "           (data_i.type == \"lab\"          and data_j.type == \"sentence\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8888093-a78b-402a-8bb1-433adeeff496",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_data_pairs(pat):\n",
    "    processed_pairs = []  # for dataframe + csv\n",
    "    data_inst_pairs = []  # for pipeline, list of tuples: ((Data 1, Data 2), label)\n",
    "    pair_idx = 0\n",
    "\n",
    "    # Iterate over all of the patient's DailyData instances (e.g. note, prescription order, lab results for same day)\n",
    "    ## pat.dailydata = {[date]: [DailyData instance from that date], ...}\n",
    "    for day, pat_dailydatas in pat.dailydata.items(): # pat_dailydatas is list of all DailyData instances for `day`\n",
    "        print(f\"********** Processing data for {day} **********\")\n",
    "        # Collect all the daily datas (note, prescription orders, lab results) for current day\n",
    "        current_dds = []\n",
    "        current_dds_features = []\n",
    "        current_dds_txts = []\n",
    "        current_dds_sem_types = []\n",
    "        current_dds_sem_names = []\n",
    "        for dd in pat_dailydatas: # iterating over DailyData instances, e.g. dd=physician note taken on `day`\n",
    "            current_dds.extend(dd.datas)\n",
    "            current_dds_features.extend(dd.datas_features)\n",
    "            current_dds_txts.extend(dd.datas_txts)\n",
    "            current_dds_sem_types.extend(dd.datas_semantic_types)\n",
    "            current_dds_sem_names.extend(dd.datas_semantic_names)\n",
    "\n",
    "        current_dds           = np.array(current_dds)\n",
    "        current_dds_features  = np.array(current_dds_features)\n",
    "        current_dds_txts      = np.array(current_dds_txts)\n",
    "        current_dds_sem_types = np.array(current_dds_sem_types)\n",
    "        current_dds_sem_names = np.array(current_dds_sem_names)\n",
    "\n",
    "        # extract similar sentences for each semantic type\n",
    "        for sem_type in SEMANTIC_TYPES:\n",
    "            # data for this semantic type\n",
    "            sem_type_bools   = [sem_type in x for x in current_dds_sem_types]\n",
    "            sem_type_indices = np.where(sem_type_bools)[0]\n",
    "            indices_map = dict(\n",
    "                            zip(range(len(sem_type_indices)), \n",
    "                                sem_type_indices)\n",
    "                          )  # maps regular indices in sem_type_current_dds_* lists to indices in current_dds_* lists\n",
    "\n",
    "            sem_type_current_dds           = current_dds[sem_type_indices]\n",
    "            sem_type_current_dds_features  = current_dds_features[sem_type_indices]\n",
    "            sem_type_current_dds_txts      = current_dds_txts[sem_type_indices]\n",
    "            sem_type_current_dds_sem_types = current_dds_sem_types[sem_type_indices]\n",
    "            sem_type_current_dds_sem_names = current_dds_sem_names[sem_type_indices]\n",
    "\n",
    "            # current_dds_featuresfor features (umls + rxnorm concepts)\n",
    "            vectorizer = CountVectorizer()\n",
    "            corpus = list(map(lambda x: ' '.join(x), sem_type_current_dds_features))\n",
    "            if len(corpus) == 0: # skip rest if no candidate sentences exist\n",
    "                continue\n",
    "            X = vectorizer.fit_transform(corpus)\n",
    "            X = X.toarray()\n",
    "\n",
    "            # get cosine similarity using umls + rxnorm concepts\n",
    "            similarity = cosine_similarity(X)     # larger=more similar\n",
    "            sim_is, sim_js = np.where(similarity>0.5) # all pairs with at least 0.5 similarity\n",
    "\n",
    "            for i, j in zip(sim_is, sim_js):\n",
    "                data_i = sem_type_current_dds[i]\n",
    "                data_j = sem_type_current_dds[j]\n",
    "                # removing same sentence pairs, checking dates\n",
    "                if i>j and is_comparable_type(data_i, data_j):\n",
    "                    print(f\"***** PAIR INDEX {pair_idx} *****\")\n",
    "                    print(f\"Cosine similarity: {similarity[i, j]}\")\n",
    "                    print(f\"----- Data i -----\")\n",
    "                    print(f\">> Time: {data_i.time}\\n\" +\\\n",
    "                          f\">> Type: {data_i.type}\\n\" +\\\n",
    "                          f\">> Concepts: {data_i.features}\\n\" +\\\n",
    "                          f\">> {data_i.txt}\")\n",
    "                    print(f\"----- Data j -----\")\n",
    "                    print(f\">> Time: {data_j.time}\\n\" +\\\n",
    "                          f\">> Type: {data_j.type}\\n\" +\\\n",
    "                          f\">> Concepts: {data_j.features}\\n\" +\\\n",
    "                          f\">> {data_j.txt}\")\n",
    "                    print(\"**********************************\")\n",
    "\n",
    "                    # save\n",
    "                    processed_pairs.append([data_i.txt,      data_j.txt, \\\n",
    "                                            data_i.time,     data_j.time, \\\n",
    "                                            data_i.type,     data_j.type, \\\n",
    "                                            data_i.features, data_j.features, \\\n",
    "                                            similarity[i, j], SEMANTIC_TYPE_TO_NAME[sem_type]])\n",
    "            #                                 SEMANTIC_TYPE_TO_NAME[semantic_type]])\n",
    "\n",
    "                    data_inst_pairs.append(((data_i, data_j), None))\n",
    "                    pair_idx += 1\n",
    "\n",
    "    ###############\n",
    "    #### Final ####\n",
    "    ###############        \n",
    "    df = \\\n",
    "    pd.DataFrame(np.array(processed_pairs), \\\n",
    "                 columns=[\"sentence 1\", \"sentence 2\", \\\n",
    "                          \"time 1\", \"time 2\", \\\n",
    "                          \"type 1\", \"type 2\", \\\n",
    "                          \"concepts 1\", \"concepts 2\", \\\n",
    "                          \"cosine similarity\", \"semantic type\"])\n",
    "    \n",
    "    return df, data_inst_pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "349f8476-9cb5-48d1-8b5d-6e395e392258",
   "metadata": {},
   "source": [
    "## README: Store generated data here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2d4a6b-bed9-457f-b8e5-9763dbea2278",
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_data_dict = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6882798-d300-43ee-b379-98b236e608e3",
   "metadata": {},
   "source": [
    "## Patient 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f3a2d5-d11c-40b3-bbaf-78fee6cc1d7c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#### Process patient data and iterate over pairs of Data instances to get pairs\n",
    "# Step 1: Select a patient -- processes all the data\n",
    "hadm_id = hadm_ids[0] # Note: `hadm_ids` is a list of all HADM id's with consecutive physician notes\n",
    "\n",
    "# for storing data\n",
    "generated_data_dict[int(hadm_id)] = {\"contradiction\": {}, \"none\": []}\n",
    "\n",
    "print(f\"Patient {int(hadm_id)}\")\n",
    "\n",
    "pat = Patient(hadm_id, notes_df, drug_df, lab_df, d_lab_df, \\\n",
    "              med7_nlp, umls_nlp, rxnorm_nlp, umls_linker, rxnorm_linker, \\\n",
    "              physician_only=True)\n",
    "\n",
    "# Making data directory\n",
    "processed_dir = 'processed'\n",
    "os.makedirs(processed_dir, exist_ok=True)\n",
    "\n",
    "pt_csv = os.path.join(processed_dir, f\"{int(hadm_id)}.csv\")\n",
    "\n",
    "# Step 2: Generate pairs for this patient\n",
    "df, data_inst_pairs = generate_data_pairs(pat)\n",
    "\n",
    "# df.to_csv(pt_csv)\n",
    "# print(\"Data has been saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03dad8e4-1deb-4009-bd38-e520f9355fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Inserting contradictions to Sentence instances\n",
    "# IMPORTANT: We should only insert contradictions if it is a sentence from a note (\"type\" should be sentence, not lab or prescription)! \n",
    "\n",
    "# Step 3: Get all the pairs about lab values\n",
    "semantic_type_ids   = CONFLICT_TO_SEMANTIC_TYPE['test_results']\n",
    "semantic_type_names = [SEMANTIC_TYPE_TO_NAME[st_id] for st_id in semantic_type_ids]\n",
    "\n",
    "is_lab = df['semantic type'].apply(lambda x: x in semantic_type_names)\n",
    "lab_pairs_df = df.loc[(df['type 1'] == \"lab\") | (df['type 2'] == \"lab\") | is_lab]\n",
    "\n",
    "lab_pairs_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f2ac9a-87d0-4940-967d-babb53c1c94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_pairs_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14bf4258-35d7-45dd-9108-db7d7a272a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Insert contradictions\n",
    "\n",
    "# We should probably aim for 1-2 contradictions per patient. \n",
    "# So basically, copy/paste code for Steps 1-4 for each patient, and push to Github.\n",
    "# Small heads up -- for a given patient, try not to insert contradictions \n",
    "# into two sentences that look really really similar. \n",
    "# There's a chance this might refer to the same underlying Sentence instance, \n",
    "# which could overwrite a contradiction you previously inserted. \n",
    "\n",
    "# Look through the sentence pairs by going through `prescription_pairs_df`.\n",
    "# If you find a good one you want to insert a contradiction for, \n",
    "# make note of the row index (i.e. the number at the left), \n",
    "# and set this to `pair_idx` below. \n",
    "# Also make note of which sentence (i.e. sentence 1 or sentence 2)\n",
    "# you want to modify, and set the `is_sentence2` flag appropriately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a04d31-b238-4513-9d93-5a22171d14d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pair_idx = 43\n",
    "is_sentence2 = True\n",
    "\n",
    "data_1 = data_inst_pairs[pair_idx][0][0]\n",
    "data_2 = data_inst_pairs[pair_idx][0][1]\n",
    "\n",
    "print(f\"{data_1.type} 1:\\t{data_1.txt}\")\n",
    "print(f\"{data_2.type} 2:\\t{data_2.txt}\")\n",
    "\n",
    "sentence_to_modify = data_inst_pairs[pair_idx][0][is_sentence2]\n",
    "\n",
    "# Set `contradicting_txt` to the new contradicting sentence.\n",
    "# This will just update the text for now.\n",
    "\n",
    "contradicting_txt = \"Potassium stable and normal range.\"\n",
    "sentence_to_modify.update_text(contradicting_txt)\n",
    "\n",
    "print(f\"\\nNew contradicting sentence: {contradicting_txt}\")\n",
    "\n",
    "# Store conflict\n",
    "generated_data_dict[int(hadm_id)]['contradiction'][pair_idx] = (is_sentence2, contradicting_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a03a6b-9d57-4809-9b4a-fd0eac5c8b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_contradiction_pair_idx = [115, 172]\n",
    "\n",
    "print(\"Examples of non-contradictions\")\n",
    "print(\"*****************************\")\n",
    "for pair_idx in no_contradiction_pair_idx:\n",
    "    data_1 = data_inst_pairs[pair_idx][0][0]\n",
    "    data_2 = data_inst_pairs[pair_idx][0][1]\n",
    "    \n",
    "    print(f\"{data_1.type} 1:\\t{data_1.txt}\")\n",
    "    print(f\"{data_2.type} 2:\\t{data_2.txt}\")\n",
    "    print(\"*****************************\")\n",
    "    \n",
    "# Store negative examples\n",
    "generated_data_dict[int(hadm_id)]['none'] = no_contradiction_pair_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "476f2d38-ba76-4fbe-9f0c-308e6de5c2f8",
   "metadata": {},
   "source": [
    "## Patient 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46349125-e902-48ee-9865-fb7a3877760f",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#### Process patient data and iterate over pairs of Data instances to get pairs\n",
    "# Step 1: Select a patient -- processes all the data\n",
    "hadm_id = hadm_ids[1] # Note: `hadm_ids` is a list of all HADM id's with consecutive physician notes\n",
    "\n",
    "# for storing data\n",
    "generated_data_dict[int(hadm_id)] = {\"contradiction\": {}, \"none\": []}\n",
    "\n",
    "print(f\"Patient {int(hadm_id)}\")\n",
    "\n",
    "pat = Patient(hadm_id, notes_df, drug_df, lab_df, d_lab_df, \\\n",
    "              med7_nlp, umls_nlp, rxnorm_nlp, umls_linker, rxnorm_linker, \\\n",
    "              physician_only=True)\n",
    "\n",
    "# Making data directory\n",
    "processed_dir = 'processed'\n",
    "os.makedirs(processed_dir, exist_ok=True)\n",
    "\n",
    "pt_csv = os.path.join(processed_dir, f\"{int(hadm_id)}.csv\")\n",
    "\n",
    "# Step 2: Generate pairs for this patient\n",
    "df, data_inst_pairs = generate_data_pairs(pat)\n",
    "\n",
    "# df.to_csv(pt_csv)\n",
    "# print(\"Data has been saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2b23cb-6645-4afd-82a6-5fa750be3ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Inserting contradictions to Sentence instances\n",
    "# IMPORTANT: We should only insert contradictions if it is a sentence from a note (\"type\" should be sentence, not lab or prescription)! \n",
    "\n",
    "# Step 3: Get all the pairs about lab values\n",
    "semantic_type_ids   = CONFLICT_TO_SEMANTIC_TYPE['test_results']\n",
    "semantic_type_names = [SEMANTIC_TYPE_TO_NAME[st_id] for st_id in semantic_type_ids]\n",
    "\n",
    "is_lab = df['semantic type'].apply(lambda x: x in semantic_type_names)\n",
    "lab_pairs_df = df.loc[(df['type 1'] == \"lab\") | (df['type 2'] == \"lab\") | is_lab]\n",
    "\n",
    "lab_pairs_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e41339c-45ef-458c-8521-79b283fd7b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_pairs_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9750d09d-1018-4a66-be7d-30c2870a6348",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Insert contradictions\n",
    "\n",
    "# We should probably aim for 1-2 contradictions per patient. \n",
    "# So basically, copy/paste code for Steps 1-4 for each patient, and push to Github.\n",
    "# Small heads up -- for a given patient, try not to insert contradictions \n",
    "# into two sentences that look really really similar. \n",
    "# There's a chance this might refer to the same underlying Sentence instance, \n",
    "# which could overwrite a contradiction you previously inserted. \n",
    "\n",
    "# Look through the sentence pairs by going through `prescription_pairs_df`.\n",
    "# If you find a good one you want to insert a contradiction for, \n",
    "# make note of the row index (i.e. the number at the left), \n",
    "# and set this to `pair_idx` below. \n",
    "# Also make note of which sentence (i.e. sentence 1 or sentence 2)\n",
    "# you want to modify, and set the `is_sentence2` flag appropriately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd5efda-b3f8-4669-9f40-02ffc21ba179",
   "metadata": {},
   "outputs": [],
   "source": [
    "pair_idx = 12\n",
    "is_sentence2 = True\n",
    "\n",
    "data_1 = data_inst_pairs[pair_idx][0][0]\n",
    "data_2 = data_inst_pairs[pair_idx][0][1]\n",
    "\n",
    "print(f\"{data_1.type} 1:\\t{data_1.txt}\")\n",
    "print(f\"{data_2.type} 2:\\t{data_2.txt}\")\n",
    "\n",
    "sentence_to_modify = data_inst_pairs[pair_idx][0][is_sentence2]\n",
    "\n",
    "# Set `contradicting_txt` to the new contradicting sentence.\n",
    "# This will just update the text for now.\n",
    "\n",
    "contradicting_txt = \"Consistently low potassium levels.\"\n",
    "sentence_to_modify.update_text(contradicting_txt)\n",
    "\n",
    "print(f\"\\nNew contradicting sentence: {contradicting_txt}\")\n",
    "\n",
    "# Store conflict\n",
    "generated_data_dict[int(hadm_id)]['contradiction'][pair_idx] = (is_sentence2, contradicting_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9408e0a6-fbe1-4085-84c8-45d05eef29d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_contradiction_pair_idx = [15, 36]\n",
    "\n",
    "print(\"Examples of non-contradictions\")\n",
    "print(\"*****************************\")\n",
    "for pair_idx in no_contradiction_pair_idx:\n",
    "    data_1 = data_inst_pairs[pair_idx][0][0]\n",
    "    data_2 = data_inst_pairs[pair_idx][0][1]\n",
    "    \n",
    "    print(f\"{data_1.type} 1:\\t{data_1.txt}\")\n",
    "    print(f\"{data_2.type} 2:\\t{data_2.txt}\")\n",
    "    print(\"*****************************\")\n",
    "\n",
    "# Store negative examples\n",
    "generated_data_dict[int(hadm_id)]['none'] = no_contradiction_pair_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040c8f72-8261-48e8-aaf3-bd4c363bff4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Todo: ask Dr. Saenz\n",
    "\"\"\"\n",
    "potential_contradiction_pair_indices = [21]\n",
    "\n",
    "print(\"Potential examples of contradictions\")\n",
    "print(\"*****************************\")\n",
    "for pair_idx in potential_contradiction_pair_indices:\n",
    "    data_1 = data_inst_pairs[pair_idx][0][0]\n",
    "    data_2 = data_inst_pairs[pair_idx][0][1]\n",
    "    \n",
    "    print(f\"{data_1.type} 1:\\t{data_1.txt}\")\n",
    "    print(f\"{data_2.type} 2:\\t{data_2.txt}\")\n",
    "    print(\"*****************************\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f1cce5f-9388-4ff5-a0c4-5ab4ee63024c",
   "metadata": {},
   "source": [
    "## Patient 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a516ad7-febb-49b2-b06f-fdbf8ecad1d2",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#### Process patient data and iterate over pairs of Data instances to get pairs\n",
    "# Step 1: Select a patient -- processes all the data\n",
    "hadm_id = hadm_ids[2] # Note: `hadm_ids` is a list of all HADM id's with consecutive physician notes\n",
    "\n",
    "# for storing data\n",
    "generated_data_dict[int(hadm_id)] = {\"contradiction\": {}, \"none\": []}\n",
    "\n",
    "print(f\"Patient {int(hadm_id)}\")\n",
    "\n",
    "pat = Patient(hadm_id, notes_df, drug_df, lab_df, d_lab_df, \\\n",
    "              med7_nlp, umls_nlp, rxnorm_nlp, umls_linker, rxnorm_linker, \\\n",
    "              physician_only=True)\n",
    "\n",
    "# Making data directory\n",
    "processed_dir = 'processed'\n",
    "os.makedirs(processed_dir, exist_ok=True)\n",
    "\n",
    "pt_csv = os.path.join(processed_dir, f\"{int(hadm_id)}.csv\")\n",
    "\n",
    "# Step 2: Generate pairs for this patient\n",
    "df, data_inst_pairs = generate_data_pairs(pat)\n",
    "\n",
    "# df.to_csv(pt_csv)\n",
    "# print(\"Data has been saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596eeab6-e695-4b18-9bfe-e30a1524762b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Inserting contradictions to Sentence instances\n",
    "# IMPORTANT: We should only insert contradictions if it is a sentence from a note (\"type\" should be sentence, not lab or prescription)! \n",
    "\n",
    "# Step 3: Get all the pairs about lab values\n",
    "semantic_type_ids   = CONFLICT_TO_SEMANTIC_TYPE['test_results']\n",
    "semantic_type_names = [SEMANTIC_TYPE_TO_NAME[st_id] for st_id in semantic_type_ids]\n",
    "\n",
    "is_lab = df['semantic type'].apply(lambda x: x in semantic_type_names)\n",
    "lab_pairs_df = df.loc[(df['type 1'] == \"lab\") | (df['type 2'] == \"lab\") | is_lab]\n",
    "\n",
    "lab_pairs_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d135ef-4c62-42c6-b5a8-bce1b5a076e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_pairs_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c54e3aa-ea7a-4be1-8abe-3dc8232422b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Insert contradictions\n",
    "\n",
    "# We should probably aim for 1-2 contradictions per patient. \n",
    "# So basically, copy/paste code for Steps 1-4 for each patient, and push to Github.\n",
    "# Small heads up -- for a given patient, try not to insert contradictions \n",
    "# into two sentences that look really really similar. \n",
    "# There's a chance this might refer to the same underlying Sentence instance, \n",
    "# which could overwrite a contradiction you previously inserted. \n",
    "\n",
    "# Look through the sentence pairs by going through `prescription_pairs_df`.\n",
    "# If you find a good one you want to insert a contradiction for, \n",
    "# make note of the row index (i.e. the number at the left), \n",
    "# and set this to `pair_idx` below. \n",
    "# Also make note of which sentence (i.e. sentence 1 or sentence 2)\n",
    "# you want to modify, and set the `is_sentence2` flag appropriately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363b18b1-bae4-458e-8401-bf62acd99437",
   "metadata": {},
   "outputs": [],
   "source": [
    "pair_idx = 46\n",
    "is_sentence2 = True\n",
    "\n",
    "data_1 = data_inst_pairs[pair_idx][0][0]\n",
    "data_2 = data_inst_pairs[pair_idx][0][1]\n",
    "\n",
    "print(f\"{data_1.type} 1:\\t{data_1.txt}\")\n",
    "print(f\"{data_2.type} 2:\\t{data_2.txt}\")\n",
    "\n",
    "sentence_to_modify = data_inst_pairs[pair_idx][0][is_sentence2]\n",
    "\n",
    "# Set `contradicting_txt` to the new contradicting sentence.\n",
    "# This will just update the text for now.\n",
    "\n",
    "contradicting_txt = \"Pt lactate stable and normal range.\"\n",
    "sentence_to_modify.update_text(contradicting_txt)\n",
    "\n",
    "print(f\"\\nNew contradicting sentence: {contradicting_txt}\")\n",
    "\n",
    "# Store conflict\n",
    "generated_data_dict[int(hadm_id)]['contradiction'][pair_idx] = (is_sentence2, contradicting_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc3fa45-398c-4c07-96cc-94b972116efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_contradiction_pair_idx = [48, 76]\n",
    "\n",
    "print(\"Examples of non-contradictions\")\n",
    "print(\"*****************************\")\n",
    "for pair_idx in no_contradiction_pair_idx:\n",
    "    data_1 = data_inst_pairs[pair_idx][0][0]\n",
    "    data_2 = data_inst_pairs[pair_idx][0][1]\n",
    "    \n",
    "    print(f\"{data_1.type} 1:\\t{data_1.txt}\")\n",
    "    print(f\"{data_2.type} 2:\\t{data_2.txt}\")\n",
    "    print(\"*****************************\")\n",
    "    \n",
    "# Store negative examples\n",
    "generated_data_dict[int(hadm_id)]['none'] = no_contradiction_pair_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a44752-956c-4611-8e17-bac081fc2e91",
   "metadata": {},
   "source": [
    "## Patient 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca31e4f-3b8a-42e9-beb4-6e9db4ce9832",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#### Process patient data and iterate over pairs of Data instances to get pairs\n",
    "# Step 1: Select a patient -- processes all the data\n",
    "hadm_id = hadm_ids[3] # Note: `hadm_ids` is a list of all HADM id's with consecutive physician notes\n",
    "\n",
    "# for storing data\n",
    "generated_data_dict[int(hadm_id)] = {\"contradiction\": {}, \"none\": []}\n",
    "\n",
    "print(f\"Patient {int(hadm_id)}\")\n",
    "\n",
    "pat = Patient(hadm_id, notes_df, drug_df, lab_df, d_lab_df, \\\n",
    "              med7_nlp, umls_nlp, rxnorm_nlp, umls_linker, rxnorm_linker, \\\n",
    "              physician_only=True)\n",
    "\n",
    "# Making data directory\n",
    "processed_dir = 'processed'\n",
    "os.makedirs(processed_dir, exist_ok=True)\n",
    "\n",
    "pt_csv = os.path.join(processed_dir, f\"{int(hadm_id)}.csv\")\n",
    "\n",
    "# Step 2: Generate pairs for this patient\n",
    "df, data_inst_pairs = generate_data_pairs(pat)\n",
    "\n",
    "# df.to_csv(pt_csv)\n",
    "# print(\"Data has been saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a610bea-62a1-48da-b7b2-869333132a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Inserting contradictions to Sentence instances\n",
    "# IMPORTANT: We should only insert contradictions if it is a sentence from a note (\"type\" should be sentence, not lab or prescription)! \n",
    "\n",
    "# Step 3: Get all the pairs about lab values\n",
    "semantic_type_ids   = CONFLICT_TO_SEMANTIC_TYPE['test_results']\n",
    "semantic_type_names = [SEMANTIC_TYPE_TO_NAME[st_id] for st_id in semantic_type_ids]\n",
    "\n",
    "is_lab = df['semantic type'].apply(lambda x: x in semantic_type_names)\n",
    "lab_pairs_df = df.loc[(df['type 1'] == \"lab\") | (df['type 2'] == \"lab\") | is_lab]\n",
    "\n",
    "lab_pairs_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae4b358-3f30-4aac-83de-e6e21eb27d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_pairs_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3dbee2-cf1e-44c6-8ce8-a593509226fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Insert contradictions\n",
    "\n",
    "# We should probably aim for 1-2 contradictions per patient. \n",
    "# So basically, copy/paste code for Steps 1-4 for each patient, and push to Github.\n",
    "# Small heads up -- for a given patient, try not to insert contradictions \n",
    "# into two sentences that look really really similar. \n",
    "# There's a chance this might refer to the same underlying Sentence instance, \n",
    "# which could overwrite a contradiction you previously inserted. \n",
    "\n",
    "# Look through the sentence pairs by going through `prescription_pairs_df`.\n",
    "# If you find a good one you want to insert a contradiction for, \n",
    "# make note of the row index (i.e. the number at the left), \n",
    "# and set this to `pair_idx` below. \n",
    "# Also make note of which sentence (i.e. sentence 1 or sentence 2)\n",
    "# you want to modify, and set the `is_sentence2` flag appropriately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9566018-823f-4d4d-b74f-0d2d77837933",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_contradiction_pair_idx = [39, 42, 72]\n",
    "\n",
    "print(\"Examples of non-contradictions\")\n",
    "print(\"*****************************\")\n",
    "for pair_idx in no_contradiction_pair_idx:\n",
    "    data_1 = data_inst_pairs[pair_idx][0][0]\n",
    "    data_2 = data_inst_pairs[pair_idx][0][1]\n",
    "    \n",
    "    print(f\"{data_1.type} 1:\\t{data_1.txt}\")\n",
    "    print(f\"{data_2.type} 2:\\t{data_2.txt}\")\n",
    "    print(\"*****************************\")\n",
    "    \n",
    "# Store negative examples\n",
    "generated_data_dict[int(hadm_id)]['none'] = no_contradiction_pair_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20443396-6c87-4bc8-8283-f17b6d9d19ed",
   "metadata": {},
   "source": [
    "## Patient 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d54e2d-00e5-4cdd-8726-da4577fb013d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#### Process patient data and iterate over pairs of Data instances to get pairs\n",
    "# Step 1: Select a patient -- processes all the data\n",
    "hadm_id = hadm_ids[4] # Note: `hadm_ids` is a list of all HADM id's with consecutive physician notes\n",
    "\n",
    "# for storing data\n",
    "generated_data_dict[int(hadm_id)] = {\"contradiction\": {}, \"none\": []}\n",
    "\n",
    "print(f\"Patient {int(hadm_id)}\")\n",
    "\n",
    "pat = Patient(hadm_id, notes_df, drug_df, lab_df, d_lab_df, \\\n",
    "              med7_nlp, umls_nlp, rxnorm_nlp, umls_linker, rxnorm_linker, \\\n",
    "              physician_only=True)\n",
    "\n",
    "# Making data directory\n",
    "processed_dir = 'processed'\n",
    "os.makedirs(processed_dir, exist_ok=True)\n",
    "\n",
    "pt_csv = os.path.join(processed_dir, f\"{int(hadm_id)}.csv\")\n",
    "\n",
    "# Step 2: Generate pairs for this patient\n",
    "df, data_inst_pairs = generate_data_pairs(pat)\n",
    "\n",
    "# df.to_csv(pt_csv)\n",
    "# print(\"Data has been saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84d310e-eeb9-45e3-8577-48e7b5478734",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Inserting contradictions to Sentence instances\n",
    "# IMPORTANT: We should only insert contradictions if it is a sentence from a note (\"type\" should be sentence, not lab or prescription)! \n",
    "\n",
    "# Step 3: Get all the pairs about lab values\n",
    "semantic_type_ids   = CONFLICT_TO_SEMANTIC_TYPE['test_results']\n",
    "semantic_type_names = [SEMANTIC_TYPE_TO_NAME[st_id] for st_id in semantic_type_ids]\n",
    "\n",
    "is_lab = df['semantic type'].apply(lambda x: x in semantic_type_names)\n",
    "lab_pairs_df = df.loc[(df['type 1'] == \"lab\") | (df['type 2'] == \"lab\") | is_lab]\n",
    "\n",
    "lab_pairs_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83f299a-0ccf-448c-9862-d5fb73c8fdde",
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_pairs_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de101f70-b340-4e42-8b9b-0595551938bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Insert contradictions\n",
    "\n",
    "# We should probably aim for 1-2 contradictions per patient. \n",
    "# So basically, copy/paste code for Steps 1-4 for each patient, and push to Github.\n",
    "# Small heads up -- for a given patient, try not to insert contradictions \n",
    "# into two sentences that look really really similar. \n",
    "# There's a chance this might refer to the same underlying Sentence instance, \n",
    "# which could overwrite a contradiction you previously inserted. \n",
    "\n",
    "# Look through the sentence pairs by going through `prescription_pairs_df`.\n",
    "# If you find a good one you want to insert a contradiction for, \n",
    "# make note of the row index (i.e. the number at the left), \n",
    "# and set this to `pair_idx` below. \n",
    "# Also make note of which sentence (i.e. sentence 1 or sentence 2)\n",
    "# you want to modify, and set the `is_sentence2` flag appropriately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24faa26d-eff1-4c58-9651-8159c6637ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pair_idx = 110\n",
    "is_sentence2 = True\n",
    "\n",
    "data_1 = data_inst_pairs[pair_idx][0][0]\n",
    "data_2 = data_inst_pairs[pair_idx][0][1]\n",
    "\n",
    "print(f\"{data_1.type} 1:\\t{data_1.txt}\")\n",
    "print(f\"{data_2.type} 2:\\t{data_2.txt}\")\n",
    "\n",
    "sentence_to_modify = data_inst_pairs[pair_idx][0][is_sentence2]\n",
    "\n",
    "# Set `contradicting_txt` to the new contradicting sentence.\n",
    "# This will just update the text for now.\n",
    "\n",
    "contradicting_txt = data_2.txt\n",
    "start, end = re.search(\"7.3\", contradicting_txt).span()\n",
    "contradicting_txt = contradicting_txt[:start] + \"1.2\" + contradicting_txt[end:]\n",
    "\n",
    "start, end = re.search(\"7.3\", contradicting_txt).span()\n",
    "contradicting_txt = contradicting_txt[:start] + \"2.4\" + contradicting_txt[end:]\n",
    "sentence_to_modify.update_text(contradicting_txt)\n",
    "\n",
    "print(f\"\\nNew contradicting sentence: {contradicting_txt}\")\n",
    "\n",
    "# Store conflict\n",
    "generated_data_dict[int(hadm_id)]['contradiction'][pair_idx] = (is_sentence2, contradicting_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99bb2b2d-b61b-4528-a715-c6f69a4f57c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_contradiction_pair_idx = [89]\n",
    "\n",
    "print(\"Examples of non-contradictions\")\n",
    "print(\"*****************************\")\n",
    "for pair_idx in no_contradiction_pair_idx:\n",
    "    data_1 = data_inst_pairs[pair_idx][0][0]\n",
    "    data_2 = data_inst_pairs[pair_idx][0][1]\n",
    "    \n",
    "    print(f\"{data_1.type} 1:\\t{data_1.txt}\")\n",
    "    print(f\"{data_2.type} 2:\\t{data_2.txt}\")\n",
    "    print(\"*****************************\")\n",
    "    \n",
    "# Store negative examples\n",
    "generated_data_dict[int(hadm_id)]['none'] = no_contradiction_pair_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28588ba8-4975-42d9-af30-57a05cca8f7e",
   "metadata": {},
   "source": [
    "## Patient 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc2a4ba-41c6-4281-be43-0f3130ed65f3",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#### Process patient data and iterate over pairs of Data instances to get pairs\n",
    "# Step 1: Select a patient -- processes all the data\n",
    "hadm_id = hadm_ids[5] # Note: `hadm_ids` is a list of all HADM id's with consecutive physician notes\n",
    "\n",
    "# for storing data\n",
    "generated_data_dict[int(hadm_id)] = {\"contradiction\": {}, \"none\": []}\n",
    "\n",
    "print(f\"Patient {int(hadm_id)}\")\n",
    "\n",
    "pat = Patient(hadm_id, notes_df, drug_df, lab_df, d_lab_df, \\\n",
    "              med7_nlp, umls_nlp, rxnorm_nlp, umls_linker, rxnorm_linker, \\\n",
    "              physician_only=True)\n",
    "\n",
    "# Making data directory\n",
    "processed_dir = 'processed'\n",
    "os.makedirs(processed_dir, exist_ok=True)\n",
    "\n",
    "pt_csv = os.path.join(processed_dir, f\"{int(hadm_id)}.csv\")\n",
    "\n",
    "# Step 2: Generate pairs for this patient\n",
    "df, data_inst_pairs = generate_data_pairs(pat)\n",
    "\n",
    "# df.to_csv(pt_csv)\n",
    "# print(\"Data has been saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bcbba33-1962-44e7-8b6f-c6cdaa9fe047",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Inserting contradictions to Sentence instances\n",
    "# IMPORTANT: We should only insert contradictions if it is a sentence from a note (\"type\" should be sentence, not lab or prescription)! \n",
    "\n",
    "# Step 3: Get all the pairs about lab values\n",
    "semantic_type_ids   = CONFLICT_TO_SEMANTIC_TYPE['test_results']\n",
    "semantic_type_names = [SEMANTIC_TYPE_TO_NAME[st_id] for st_id in semantic_type_ids]\n",
    "\n",
    "is_lab = df['semantic type'].apply(lambda x: x in semantic_type_names)\n",
    "lab_pairs_df = df.loc[(df['type 1'] == \"lab\") | (df['type 2'] == \"lab\") | is_lab]\n",
    "\n",
    "lab_pairs_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539a96ca-8bae-4b58-b76e-0d35f41fe413",
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_pairs_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7828fbb-b11c-479c-a1ab-629c647e9105",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Insert contradictions\n",
    "\n",
    "# We should probably aim for 1-2 contradictions per patient. \n",
    "# So basically, copy/paste code for Steps 1-4 for each patient, and push to Github.\n",
    "# Small heads up -- for a given patient, try not to insert contradictions \n",
    "# into two sentences that look really really similar. \n",
    "# There's a chance this might refer to the same underlying Sentence instance, \n",
    "# which could overwrite a contradiction you previously inserted. \n",
    "\n",
    "# Look through the sentence pairs by going through `prescription_pairs_df`.\n",
    "# If you find a good one you want to insert a contradiction for, \n",
    "# make note of the row index (i.e. the number at the left), \n",
    "# and set this to `pair_idx` below. \n",
    "# Also make note of which sentence (i.e. sentence 1 or sentence 2)\n",
    "# you want to modify, and set the `is_sentence2` flag appropriately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b09277-3952-4d0c-9a18-0a472b40a972",
   "metadata": {},
   "outputs": [],
   "source": [
    "pair_idx = 21\n",
    "is_sentence2 = True\n",
    "\n",
    "data_1 = data_inst_pairs[pair_idx][0][0]\n",
    "data_2 = data_inst_pairs[pair_idx][0][1]\n",
    "\n",
    "print(f\"{data_1.type} 1:\\t{data_1.txt}\")\n",
    "print(f\"{data_2.type} 2:\\t{data_2.txt}\")\n",
    "\n",
    "sentence_to_modify = data_inst_pairs[pair_idx][0][is_sentence2]\n",
    "\n",
    "# Set `contradicting_txt` to the new contradicting sentence.\n",
    "# This will just update the text for now.\n",
    "\n",
    "contradicting_txt = \"Attending    Evaluated pt who had normal resp \" +\\\n",
    "                    \"with ABG no evidence of fatigue.\"\n",
    "sentence_to_modify.update_text(contradicting_txt)\n",
    "\n",
    "print(f\"\\nNew contradicting sentence: {contradicting_txt}\")\n",
    "\n",
    "# Store conflict\n",
    "generated_data_dict[int(hadm_id)]['contradiction'][pair_idx] = (is_sentence2, contradicting_txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a843b751-70cc-4800-b77a-27cd9ad55873",
   "metadata": {},
   "source": [
    "## Patient 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098db7a2-6273-4535-a45f-51a366b0f081",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#### Process patient data and iterate over pairs of Data instances to get pairs\n",
    "# Step 1: Select a patient -- processes all the data\n",
    "hadm_id = hadm_ids[3] # Note: `hadm_ids` is a list of all HADM id's with consecutive physician notes\n",
    "\n",
    "# for storing data\n",
    "generated_data_dict[int(hadm_id)] = {\"contradiction\": {}, \"none\": []}\n",
    "\n",
    "print(f\"Patient {int(hadm_id)}\")\n",
    "\n",
    "pat = Patient(hadm_id, notes_df, drug_df, lab_df, d_lab_df, \\\n",
    "              med7_nlp, umls_nlp, rxnorm_nlp, umls_linker, rxnorm_linker, \\\n",
    "              physician_only=True)\n",
    "\n",
    "# Making data directory\n",
    "processed_dir = 'processed'\n",
    "os.makedirs(processed_dir, exist_ok=True)\n",
    "\n",
    "pt_csv = os.path.join(processed_dir, f\"{int(hadm_id)}.csv\")\n",
    "\n",
    "# Step 2: Generate pairs for this patient\n",
    "df, data_inst_pairs = generate_data_pairs(pat)\n",
    "\n",
    "# df.to_csv(pt_csv)\n",
    "# print(\"Data has been saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef09c97-67bc-4508-a9f1-506ebcf46ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Inserting contradictions to Sentence instances\n",
    "# IMPORTANT: We should only insert contradictions if it is a sentence from a note (\"type\" should be sentence, not lab or prescription)! \n",
    "\n",
    "# Step 3: Get all the pairs about lab values\n",
    "semantic_type_ids   = CONFLICT_TO_SEMANTIC_TYPE['test_results']\n",
    "semantic_type_names = [SEMANTIC_TYPE_TO_NAME[st_id] for st_id in semantic_type_ids]\n",
    "\n",
    "is_lab = df['semantic type'].apply(lambda x: x in semantic_type_names)\n",
    "lab_pairs_df = df.loc[(df['type 1'] == \"lab\") | (df['type 2'] == \"lab\") | is_lab]\n",
    "\n",
    "lab_pairs_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba334f5-cc89-44e7-9926-77725a2b4f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_pairs_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc123bff-2f65-4702-aa90-384ee7c68cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Insert contradictions\n",
    "\n",
    "# We should probably aim for 1-2 contradictions per patient. \n",
    "# So basically, copy/paste code for Steps 1-4 for each patient, and push to Github.\n",
    "# Small heads up -- for a given patient, try not to insert contradictions \n",
    "# into two sentences that look really really similar. \n",
    "# There's a chance this might refer to the same underlying Sentence instance, \n",
    "# which could overwrite a contradiction you previously inserted. \n",
    "\n",
    "# Look through the sentence pairs by going through `prescription_pairs_df`.\n",
    "# If you find a good one you want to insert a contradiction for, \n",
    "# make note of the row index (i.e. the number at the left), \n",
    "# and set this to `pair_idx` below. \n",
    "# Also make note of which sentence (i.e. sentence 1 or sentence 2)\n",
    "# you want to modify, and set the `is_sentence2` flag appropriately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35c5438-87f4-4d59-a720-cbe2c4621527",
   "metadata": {},
   "outputs": [],
   "source": [
    "pair_idx = 79\n",
    "is_sentence2 = True\n",
    "\n",
    "data_1 = data_inst_pairs[pair_idx][0][0]\n",
    "data_2 = data_inst_pairs[pair_idx][0][1]\n",
    "\n",
    "print(f\"{data_1.type} 1:\\t{data_1.txt}\")\n",
    "print(f\"{data_2.type} 2:\\t{data_2.txt}\")\n",
    "\n",
    "sentence_to_modify = data_inst_pairs[pair_idx][0][is_sentence2]\n",
    "\n",
    "# Set `contradicting_txt` to the new contradicting sentence.\n",
    "# This will just update the text for now.\n",
    "\n",
    "contradicting_txt = \"Labs normal range    for WBC as above, HCT 40, K+ 3.2, Cr 1.1, lactate 4.3.\"\n",
    "sentence_to_modify.update_text(contradicting_txt)\n",
    "\n",
    "print(f\"\\nNew contradicting sentence: {contradicting_txt}\")\n",
    "\n",
    "# Store conflict\n",
    "generated_data_dict[int(hadm_id)]['contradiction'][pair_idx] = (is_sentence2, contradicting_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f6c0a6-8e77-4718-96dc-8d43a3280ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_contradiction_pair_idx = [39, 42, 72, 78, 80]\n",
    "\n",
    "print(\"Examples of non-contradictions\")\n",
    "print(\"*****************************\")\n",
    "for pair_idx in no_contradiction_pair_idx:\n",
    "    data_1 = data_inst_pairs[pair_idx][0][0]\n",
    "    data_2 = data_inst_pairs[pair_idx][0][1]\n",
    "    \n",
    "    print(f\"{data_1.type} 1:\\t{data_1.txt}\")\n",
    "    print(f\"{data_2.type} 2:\\t{data_2.txt}\")\n",
    "    print(\"*****************************\")\n",
    "    \n",
    "# Store negative examples\n",
    "generated_data_dict[int(hadm_id)]['none'] = no_contradiction_pair_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9a58e6-0721-453c-996d-70dab50a7f3b",
   "metadata": {},
   "source": [
    "## Patient 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872971b7-e0b1-461b-8290-5665211c6a12",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#### Process patient data and iterate over pairs of Data instances to get pairs\n",
    "# Step 1: Select a patient -- processes all the data\n",
    "hadm_id = hadm_ids[7] # Note: `hadm_ids` is a list of all HADM id's with consecutive physician notes\n",
    "\n",
    "# for storing data\n",
    "generated_data_dict[int(hadm_id)] = {\"contradiction\": {}, \"none\": []}\n",
    "\n",
    "print(f\"Patient {int(hadm_id)}\")\n",
    "\n",
    "pat = Patient(hadm_id, notes_df, drug_df, lab_df, d_lab_df, \\\n",
    "              med7_nlp, umls_nlp, rxnorm_nlp, umls_linker, rxnorm_linker, \\\n",
    "              physician_only=True)\n",
    "\n",
    "# Making data directory\n",
    "processed_dir = 'processed'\n",
    "os.makedirs(processed_dir, exist_ok=True)\n",
    "\n",
    "pt_csv = os.path.join(processed_dir, f\"{int(hadm_id)}.csv\")\n",
    "\n",
    "# Step 2: Generate pairs for this patient\n",
    "df, data_inst_pairs = generate_data_pairs(pat)\n",
    "\n",
    "# df.to_csv(pt_csv)\n",
    "# print(\"Data has been saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62507c8d-07ad-42d2-bebb-e9c9c6503c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Inserting contradictions to Sentence instances\n",
    "# IMPORTANT: We should only insert contradictions if it is a sentence from a note (\"type\" should be sentence, not lab or prescription)! \n",
    "\n",
    "# Step 3: Get all the pairs about lab values\n",
    "semantic_type_ids   = CONFLICT_TO_SEMANTIC_TYPE['test_results']\n",
    "semantic_type_names = [SEMANTIC_TYPE_TO_NAME[st_id] for st_id in semantic_type_ids]\n",
    "\n",
    "is_lab = df['semantic type'].apply(lambda x: x in semantic_type_names)\n",
    "lab_pairs_df = df.loc[(df['type 1'] == \"lab\") | (df['type 2'] == \"lab\") | is_lab]\n",
    "\n",
    "lab_pairs_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e770b478-b378-472a-9910-961a905c675a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_pairs_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58db389d-6e57-4ae5-a60e-1ee0e72541a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Insert contradictions\n",
    "\n",
    "# We should probably aim for 1-2 contradictions per patient. \n",
    "# So basically, copy/paste code for Steps 1-4 for each patient, and push to Github.\n",
    "# Small heads up -- for a given patient, try not to insert contradictions \n",
    "# into two sentences that look really really similar. \n",
    "# There's a chance this might refer to the same underlying Sentence instance, \n",
    "# which could overwrite a contradiction you previously inserted. \n",
    "\n",
    "# Look through the sentence pairs by going through `prescription_pairs_df`.\n",
    "# If you find a good one you want to insert a contradiction for, \n",
    "# make note of the row index (i.e. the number at the left), \n",
    "# and set this to `pair_idx` below. \n",
    "# Also make note of which sentence (i.e. sentence 1 or sentence 2)\n",
    "# you want to modify, and set the `is_sentence2` flag appropriately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb3de61-b44a-4439-9330-f70c36c5fb5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pair_idx = 117\n",
    "is_sentence2 = True\n",
    "\n",
    "data_1 = data_inst_pairs[pair_idx][0][0]\n",
    "data_2 = data_inst_pairs[pair_idx][0][1]\n",
    "\n",
    "print(f\"{data_1.type} 1:\\t{data_1.txt}\")\n",
    "print(f\"{data_2.type} 2:\\t{data_2.txt}\")\n",
    "\n",
    "sentence_to_modify = data_inst_pairs[pair_idx][0][is_sentence2]\n",
    "\n",
    "# Set `contradicting_txt` to the new contradicting sentence.\n",
    "# This will just update the text for now.\n",
    "\n",
    "contradicting_txt = \"Standard WBC levels         no sign of CLL.\"\n",
    "sentence_to_modify.update_text(contradicting_txt)\n",
    "\n",
    "print(f\"\\nNew contradicting sentence: {contradicting_txt}\")\n",
    "\n",
    "# Store conflict\n",
    "generated_data_dict[int(hadm_id)]['contradiction'][pair_idx] = (is_sentence2, contradicting_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9a7d26-f234-4f15-9b97-c28f4403f1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pair_idx = 212\n",
    "is_sentence2 = True\n",
    "\n",
    "data_1 = data_inst_pairs[pair_idx][0][0]\n",
    "data_2 = data_inst_pairs[pair_idx][0][1]\n",
    "\n",
    "print(f\"{data_1.type} 1:\\t{data_1.txt}\")\n",
    "print(f\"{data_2.type} 2:\\t{data_2.txt}\")\n",
    "\n",
    "sentence_to_modify = data_inst_pairs[pair_idx][0][is_sentence2]\n",
    "\n",
    "# Set `contradicting_txt` to the new contradicting sentence.\n",
    "# This will just update the text for now.\n",
    "\n",
    "contradicting_txt = \"WBC persistently    low sign of infection.\"\n",
    "sentence_to_modify.update_text(contradicting_txt)\n",
    "\n",
    "print(f\"\\nNew contradicting sentence: {contradicting_txt}\")\n",
    "\n",
    "# Store conflict\n",
    "generated_data_dict[int(hadm_id)]['contradiction'][pair_idx] = (is_sentence2, contradicting_txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed908b6-cf2d-4d19-8b89-ee22879f08f6",
   "metadata": {},
   "source": [
    "## Patient 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3715478-7caf-4df6-a401-93a0a5321213",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#### Process patient data and iterate over pairs of Data instances to get pairs\n",
    "# Step 1: Select a patient -- processes all the data\n",
    "hadm_id = hadm_ids[8] # Note: `hadm_ids` is a list of all HADM id's with consecutive physician notes\n",
    "\n",
    "# for storing data\n",
    "generated_data_dict[int(hadm_id)] = {\"contradiction\": {}, \"none\": []}\n",
    "\n",
    "print(f\"Patient {int(hadm_id)}\")\n",
    "\n",
    "pat = Patient(hadm_id, notes_df, drug_df, lab_df, d_lab_df, \\\n",
    "              med7_nlp, umls_nlp, rxnorm_nlp, umls_linker, rxnorm_linker, \\\n",
    "              physician_only=True)\n",
    "\n",
    "# Making data directory\n",
    "processed_dir = 'processed'\n",
    "os.makedirs(processed_dir, exist_ok=True)\n",
    "\n",
    "pt_csv = os.path.join(processed_dir, f\"{int(hadm_id)}.csv\")\n",
    "\n",
    "# Step 2: Generate pairs for this patient\n",
    "df, data_inst_pairs = generate_data_pairs(pat)\n",
    "\n",
    "# df.to_csv(pt_csv)\n",
    "# print(\"Data has been saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50f809a-97d5-4703-a648-b9302c260305",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Inserting contradictions to Sentence instances\n",
    "# IMPORTANT: We should only insert contradictions if it is a sentence from a note (\"type\" should be sentence, not lab or prescription)! \n",
    "\n",
    "# Step 3: Get all the pairs about lab values\n",
    "semantic_type_ids   = CONFLICT_TO_SEMANTIC_TYPE['test_results']\n",
    "semantic_type_names = [SEMANTIC_TYPE_TO_NAME[st_id] for st_id in semantic_type_ids]\n",
    "\n",
    "is_lab = df['semantic type'].apply(lambda x: x in semantic_type_names)\n",
    "lab_pairs_df = df.loc[(df['type 1'] == \"lab\") | (df['type 2'] == \"lab\") | is_lab]\n",
    "\n",
    "lab_pairs_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcbcb4ca-12ad-42cc-abeb-c5fc39508a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_pairs_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41881cd0-8873-45a5-8166-2b7c9526eba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Insert contradictions\n",
    "\n",
    "# We should probably aim for 1-2 contradictions per patient. \n",
    "# So basically, copy/paste code for Steps 1-4 for each patient, and push to Github.\n",
    "# Small heads up -- for a given patient, try not to insert contradictions \n",
    "# into two sentences that look really really similar. \n",
    "# There's a chance this might refer to the same underlying Sentence instance, \n",
    "# which could overwrite a contradiction you previously inserted. \n",
    "\n",
    "# Look through the sentence pairs by going through `prescription_pairs_df`.\n",
    "# If you find a good one you want to insert a contradiction for, \n",
    "# make note of the row index (i.e. the number at the left), \n",
    "# and set this to `pair_idx` below. \n",
    "# Also make note of which sentence (i.e. sentence 1 or sentence 2)\n",
    "# you want to modify, and set the `is_sentence2` flag appropriately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13c4b3b-f502-46e2-80cc-abd0729d9425",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_contradiction_pair_idx = [16]\n",
    "\n",
    "print(\"Examples of non-contradictions\")\n",
    "print(\"*****************************\")\n",
    "for pair_idx in no_contradiction_pair_idx:\n",
    "    data_1 = data_inst_pairs[pair_idx][0][0]\n",
    "    data_2 = data_inst_pairs[pair_idx][0][1]\n",
    "    \n",
    "    print(f\"{data_1.type} 1:\\t{data_1.txt}\")\n",
    "    print(f\"{data_2.type} 2:\\t{data_2.txt}\")\n",
    "    print(\"*****************************\")\n",
    "    \n",
    "# Store negative examples\n",
    "generated_data_dict[int(hadm_id)]['none'] = no_contradiction_pair_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdac1f38-e5ba-4770-bbe5-f77c2b219022",
   "metadata": {},
   "source": [
    "## Patient 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86b910b-10cd-456c-8221-e7fd53d59d5b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#### Process patient data and iterate over pairs of Data instances to get pairs\n",
    "# Step 1: Select a patient -- processes all the data\n",
    "hadm_id = hadm_ids[9] # Note: `hadm_ids` is a list of all HADM id's with consecutive physician notes\n",
    "\n",
    "# for storing data\n",
    "generated_data_dict[int(hadm_id)] = {\"contradiction\": {}, \"none\": []}\n",
    "\n",
    "print(f\"Patient {int(hadm_id)}\")\n",
    "\n",
    "pat = Patient(hadm_id, notes_df, drug_df, lab_df, d_lab_df, \\\n",
    "              med7_nlp, umls_nlp, rxnorm_nlp, umls_linker, rxnorm_linker, \\\n",
    "              physician_only=True)\n",
    "\n",
    "# Making data directory\n",
    "processed_dir = 'processed'\n",
    "os.makedirs(processed_dir, exist_ok=True)\n",
    "\n",
    "pt_csv = os.path.join(processed_dir, f\"{int(hadm_id)}.csv\")\n",
    "\n",
    "# Step 2: Generate pairs for this patient\n",
    "df, data_inst_pairs = generate_data_pairs(pat)\n",
    "\n",
    "# df.to_csv(pt_csv)\n",
    "# print(\"Data has been saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e5749f-f8c6-4eb9-ba63-a3b3348be9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Inserting contradictions to Sentence instances\n",
    "# IMPORTANT: We should only insert contradictions if it is a sentence from a note (\"type\" should be sentence, not lab or prescription)! \n",
    "\n",
    "# Step 3: Get all the pairs about lab values\n",
    "semantic_type_ids   = CONFLICT_TO_SEMANTIC_TYPE['test_results']\n",
    "semantic_type_names = [SEMANTIC_TYPE_TO_NAME[st_id] for st_id in semantic_type_ids]\n",
    "\n",
    "is_lab = df['semantic type'].apply(lambda x: x in semantic_type_names)\n",
    "lab_pairs_df = df.loc[(df['type 1'] == \"lab\") | (df['type 2'] == \"lab\") | is_lab]\n",
    "\n",
    "lab_pairs_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f80a0b7-0591-4069-bbb4-0c03c60bdb51",
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_pairs_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415e7c8b-8c05-4c04-b743-7eb924ac08d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Insert contradictions\n",
    "\n",
    "# We should probably aim for 1-2 contradictions per patient. \n",
    "# So basically, copy/paste code for Steps 1-4 for each patient, and push to Github.\n",
    "# Small heads up -- for a given patient, try not to insert contradictions \n",
    "# into two sentences that look really really similar. \n",
    "# There's a chance this might refer to the same underlying Sentence instance, \n",
    "# which could overwrite a contradiction you previously inserted. \n",
    "\n",
    "# Look through the sentence pairs by going through `prescription_pairs_df`.\n",
    "# If you find a good one you want to insert a contradiction for, \n",
    "# make note of the row index (i.e. the number at the left), \n",
    "# and set this to `pair_idx` below. \n",
    "# Also make note of which sentence (i.e. sentence 1 or sentence 2)\n",
    "# you want to modify, and set the `is_sentence2` flag appropriately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aac4cf8-c4dd-4ef6-a3b0-3f6fb0ce95f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pair_idx = 48\n",
    "is_sentence2 = True\n",
    "\n",
    "data_1 = data_inst_pairs[pair_idx][0][0]\n",
    "data_2 = data_inst_pairs[pair_idx][0][1]\n",
    "\n",
    "print(f\"{data_1.type} 1:\\t{data_1.txt}\")\n",
    "print(f\"{data_2.type} 2:\\t{data_2.txt}\")\n",
    "\n",
    "sentence_to_modify = data_inst_pairs[pair_idx][0][is_sentence2]\n",
    "\n",
    "# Set `contradicting_txt` to the new contradicting sentence.\n",
    "# This will just update the text for now.\n",
    "\n",
    "contradicting_txt = \"36.5 %    12.2 g/dL    122 mg/dL    1.5 mg/dL    44 mg/dL    29 mEq/L    \" +\\\n",
    "                    \"84 mEq/L    4.3 mEq/L    120 mEq/L    12.5 K/uL         [image002.jpg]                               \" +\\\n",
    "                    \"[**2143-4-21**]   12:58 AM                               [**2143-4-21**]   04:50 AM    \" +\\\n",
    "                    \"WBC                                     12.5    Hct                                     36.5    \" +\\\n",
    "                    \"Plt                                      163    Cr                                      \" +\\\n",
    "                    \"1.5                                      1.5    TropT                                     0.03    \" +\\\n",
    "                    \"Glucose                                      130                                      122    \" +\\\n",
    "                    \"Other labs: PT / PTT / INR:14.7/290.0/1.3, CK / CKMB /    Troponin-T:30/2/0.03, ALT / AST:28/55, Alk Phos \" +\\\n",
    "                    \"/ T Bili:161/0.4,    Amylase / Lipase:27/13, Albumin:2.9 g/dL, LDH:347 IU/L, Ca++:8.2 mg/dL,    \" +\\\n",
    "                    \"Mg++:3.1 mg/dL, PO4:5.1 mg/dL'\"\n",
    "sentence_to_modify.update_text(contradicting_txt)\n",
    "\n",
    "print(f\"\\nNew contradicting sentence: {contradicting_txt}\")\n",
    "\n",
    "# Store conflict\n",
    "generated_data_dict[int(hadm_id)]['contradiction'][pair_idx] = (is_sentence2, contradicting_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95949f7-87d7-4bbc-919e-1d159496bef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_contradiction_pair_idx = [48, 49, 104]\n",
    "\n",
    "print(\"Examples of non-contradictions\")\n",
    "print(\"*****************************\")\n",
    "for pair_idx in no_contradiction_pair_idx:\n",
    "    data_1 = data_inst_pairs[pair_idx][0][0]\n",
    "    data_2 = data_inst_pairs[pair_idx][0][1]\n",
    "    \n",
    "    print(f\"{data_1.type} 1:\\t{data_1.txt}\")\n",
    "    print(f\"{data_2.type} 2:\\t{data_2.txt}\")\n",
    "    print(\"*****************************\")\n",
    "    \n",
    "# Store negative examples\n",
    "generated_data_dict[int(hadm_id)]['none'] = no_contradiction_pair_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488bb935-a76f-4ee8-aa29-b673bb081b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "data_dict_file = \"generated_data_dict_lab.pkl\"\n",
    "with open(data_dict_file, \"wb\") as f:\n",
    "    pickle.dump(generated_data_dict, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "babddaed-e9cf-4a93-8243-4ea7541fbbcd",
   "metadata": {},
   "source": [
    "# 5. Loading contradictions data for pipeline [skip 4 if pickle file already created]\n",
    "\n",
    "If `generated_data_dict_lab.pkl` has already been created, skip part 4. You should still run the inital cells, above \"README\" in that section though.\n",
    "\n",
    "About 2 min per HADM_ID, 20 min total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e522c97-d1b7-4dda-83d3-90eeb5f3e127",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9 - positive examples\n",
    "# 16 - negative examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6867825-8c0b-40fa-93d9-78aacf494caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "data_dict_files = {\"lab\": \"generated_data_dict_lab.pkl\",\n",
    "                   \"prescription\": \"generated_data_dict_prescription.pkl\",\n",
    "                   \"diagnosis\": \"generated_data_dict_diagnosis.pkl\"}\n",
    "\n",
    "data_dict_unpickled = {}\n",
    "for ctype, cfile in data_dict_files.items():\n",
    "    try:\n",
    "        with open(cfile, \"rb\") as f:\n",
    "            generated_unpickled = pickle.load(f)\n",
    "    except FileNotFoundError:\n",
    "        continue \n",
    "        \n",
    "    data_dict_unpickled[ctype] = generated_unpickled\n",
    "\n",
    "# data_dict_file = \"generated_data_dict_lab.pkl\"\n",
    "# with open(data_dict_file, \"rb\") as f:\n",
    "#     generated_data_dict = pickle.load(f)\n",
    "\n",
    "data_dict_unpickled.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609282da-09e8-4b8c-a40d-ed7e9d5e1480",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_contradictions(hadm_generated_dict, generated_dataset, conflict_type=None):\n",
    "    print(\"+++++ Inserting contradictions +++++\")\n",
    "    for pair_idx, (is_sentence2, contradicting_txt) in hadm_generated_dict['contradiction'].items():\n",
    "        data_1 = data_inst_pairs[pair_idx][0][0]\n",
    "        data_2 = data_inst_pairs[pair_idx][0][1]\n",
    "\n",
    "        print(f\"{data_1.type} 1:\\t{data_1.txt}\")\n",
    "        print(f\"{data_2.type} 2:\\t{data_2.txt}\")\n",
    "\n",
    "        sentence_to_modify = data_inst_pairs[pair_idx][0][is_sentence2]\n",
    "\n",
    "        # Set `contradicting_txt` to the new contradicting sentence.\n",
    "        # Update text and reprocess features.\n",
    "        sentence_to_modify.update_text(contradicting_txt, True)\n",
    "\n",
    "        print(f\"\\nNew contradicting sentence: {contradicting_txt}\")\n",
    "        print(\"+++++++++++++++++++++++++++++++++++\")\n",
    "        \n",
    "        # Add example to dataset\n",
    "        if is_sentence2:\n",
    "            sentences = (data_1, sentence_to_modify)\n",
    "        else:\n",
    "            sentences = (sentence_to_modify, data_2)\n",
    "            \n",
    "        if conflict_type is None:\n",
    "            generated_dataset.append((sentences, 1)) # these are all contradictions\n",
    "        else: # also add the conflict type if it is given\n",
    "            generated_dataset.append((sentences, 1, conflict_type)) # these are all contradictions\n",
    "        \n",
    "    return generated_dataset\n",
    "\n",
    "def insert_negative_ex(hadm_generated_dict, generated_dataset, conflict_type=None):\n",
    "    print(\"+++++ Inserting negative examples +++++\")\n",
    "    for pair_idx in hadm_generated_dict['none']:\n",
    "        data_1 = data_inst_pairs[pair_idx][0][0]\n",
    "        data_2 = data_inst_pairs[pair_idx][0][1]\n",
    "\n",
    "        print(f\"{data_1.type} 1:\\t{data_1.txt}\")\n",
    "        print(f\"{data_2.type} 2:\\t{data_2.txt}\")\n",
    "\n",
    "        if conflict_type is None:\n",
    "            generated_dataset.append(((data_1, data_2), 0)) # these are all negatives\n",
    "        else: # also add the conflict type if it is given\n",
    "            generated_dataset.append(((data_1, data_2), 0, conflict_type)) # these are all negatives\n",
    "#         generated_dataset.append(((data_1, data_2), 0))\n",
    "        print(\"+++++++++++++++++++++++++++++++++++\")\n",
    "        \n",
    "    return generated_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eedab464-baed-42c4-b0cf-734529f6fde3",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "generated_dataset = [] # list of tuples, ((data 1, data 2), label)\n",
    "\n",
    "for hadm_id in hadm_ids[:10]:\n",
    "    print(\"***********************************\")\n",
    "    print(f\"Patient {int(hadm_id)}\")        \n",
    "    # Step 1: Select a patient -- process all data\n",
    "    pat = Patient(hadm_id, notes_df, drug_df, lab_df, d_lab_df, \\\n",
    "                  med7_nlp, umls_nlp, rxnorm_nlp, umls_linker, rxnorm_linker, \\\n",
    "                  physician_only=True)\n",
    "\n",
    "    # Step 2: Generate pairs for this patient\n",
    "    df, data_inst_pairs = generate_data_pairs(pat)\n",
    "    \n",
    "    # Step 3: Insert contradictions + negative examples\n",
    "    for ctype, c_generated_data_dict in data_dict_unpickled.items():    \n",
    "        try:\n",
    "            c_hadm_generated_dict = c_generated_data_dict[int(hadm_id)]\n",
    "        except KeyError:\n",
    "            print(\"This patient does not exist in contradiction set.\")\n",
    "            continue\n",
    "        \n",
    "        # Step 3A: Insert contradictions \n",
    "        generated_dataset = insert_contradictions(c_hadm_generated_dict, generated_dataset, ctype)\n",
    "    \n",
    "        # Step 3B: Insert negative examples (not contradictions)\n",
    "        generated_dataset = insert_negative_ex(c_hadm_generated_dict, generated_dataset, ctype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c6a8a9-8c8b-4bad-b4df-d10a5dc5ad2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(generated_dataset)\n",
    "n_negatives = len(list(filter(lambda x: x[1]==0, generated_dataset)))\n",
    "n_positives = len(list(filter(lambda x: x[1]==1, generated_dataset)))\n",
    "\n",
    "print(f\"We have {n} total examples\\n\\t- {n_negatives} negative examples\\n\\t- {n_positives} positive examples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd41e741-48e6-4575-a09c-c1e5a517479c",
   "metadata": {},
   "source": [
    "Processing dataset for Romanov baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c89bc47-cf3e-42ed-bc67-cbb5388c660d",
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_dataset_file_unlabeled = \"processed/generated_dataset_unlabeled.txt\"\n",
    "generated_dataset_file_labeled   = \"processed/generated_dataset_labeled.txt\"\n",
    "generated_dataset_file_all       = \"processed/generated_dataset.txt\"\n",
    "\n",
    "for ((data_1, data_2), label, ctype) in generated_dataset:\n",
    "    with open(generated_dataset_file_unlabeled, \"a\") as f:\n",
    "        f.write(f\"{data_1.txt}\\t{data_2.txt}\\n\")\n",
    "        \n",
    "    with open(generated_dataset_file_labeled, \"a\") as f:\n",
    "        f.write(f\"{data_1.txt}\\t{data_2.txt}\\t{label}\\n\")\n",
    "        \n",
    "    with open(generated_dataset_file_all, \"a\") as f:\n",
    "        f.write(f\"{data_1.txt}\\t{data_2.txt}\\t{label}\\t{ctype}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d822e16-d304-42d7-9738-541803177e1a",
   "metadata": {},
   "source": [
    "## Feature Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad84f68d-12e1-4f0a-ad6c-cdb620fd84b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if number of neg tokens is equal, return 0; otherwise, return 1\n",
    "def check_if_number_neg_equal_umls(s1, s2):\n",
    "    sent_doc_1_umls = s1.umls_doc    # \"Doc\" output for UMLS \n",
    "    sent_doc_2_umls = s2.umls_doc    # \"Doc\" output for UMLS\n",
    "    \n",
    "    negation_tokens_1 = [tok for tok in sent_doc_1_umls if tok.dep_ == 'neg']\n",
    "    negation_tokens_2 = [tok for tok in sent_doc_2_umls if tok.dep_ == 'neg']\n",
    "\n",
    "    if len(negation_tokens_1) != len(negation_tokens_2):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "588023c7-949c-4d3b-8986-72b168fabe5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Get dependency tokens based on UMLS ontology\n",
    "\"\"\"\n",
    "def create_dep_encoding(s1, s2):\n",
    "\n",
    "    sent_doc_1 = s1.umls_doc\n",
    "    sent_doc_2 = s2.umls_doc\n",
    "\n",
    "    dep_child_1 = []\n",
    "    dep_child_2 = []\n",
    "\n",
    "    for token in sent_doc_1:\n",
    "        if token.dep_ == \"ROOT\": \n",
    "            index_to_check = token.i\n",
    "            dep_list_1 = [token.text for token in sent_doc_1[index_to_check].children if token.dep_ != \"punct\"]\n",
    "            dep_child_1.append(sent_doc_1[index_to_check].text)\n",
    "            dep_child_1.extend(dep_list_1)\n",
    "\n",
    "    for token in sent_doc_2:\n",
    "        if token.dep_ == \"ROOT\":\n",
    "            index_to_check = token.i\n",
    "            dep_list_2 = [token.text for token in sent_doc_2[index_to_check].children if token.dep_ != \"punct\"]\n",
    "            dep_child_2.append(sent_doc_2[index_to_check].text)\n",
    "            dep_child_2.extend(dep_list_2)\n",
    "\n",
    "    dep_sent_1 = list_to_string(dep_child_1)\n",
    "    dep_sent_2 = list_to_string(dep_child_2)\n",
    "\n",
    "    dep_doc_1 = umls_nlp(dep_sent_1)\n",
    "    dep_doc_2 = umls_nlp(dep_sent_2)\n",
    "    similarity = dep_doc_1.similarity(dep_doc_2)\n",
    "    return similarity\n",
    "\n",
    "def list_to_string(list1):\n",
    "    str1 = \"\"\n",
    "    for element in list1:\n",
    "        str1 += \" \" + element\n",
    "\n",
    "    return str1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8444c8-77b1-4b0e-983c-3642dfc71ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Given Sentence instances s1, s2\n",
    "check if they share a shared concept feature (UMLS and RxNorm concepts) \n",
    "if they do not share a concept, return 1; otherwise, return 0\n",
    "\"\"\"\n",
    "def check_shared_feature_umls(s1,s2):\n",
    "    #{'Scanning'}\n",
    "    s1_features = s1.features\n",
    "    s2_features = s2.features\n",
    "    \n",
    "    # check if share feature in common\n",
    "    shared_feature = list(set(s1_features) & set(s2_features))\n",
    "    \n",
    "    # do not share concept\n",
    "    if shared_feature != []:\n",
    "        return 1\n",
    "    else: \n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794fd532-ed8e-4e7d-ae8c-435f5b5fe394",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Med7 (prescription) entities\n",
    "# if not talking about same DRUG -> return 0\n",
    "# if same DRUG but other info different -> return 1\n",
    "\"\"\"\n",
    "def check_shared_feature_med7(s1,s2):\n",
    "    \n",
    "    # [('2U', 'DOSAGE'), ('PRBC', 'DRUG')]\n",
    "    s1_features = s1.med7_entities\n",
    "    s2_features = s2.med7_entities\n",
    "    \n",
    "    # get drug names for each sentence\n",
    "    s1_names = [name for (name, word_type) in s1_features if word_type == \"DRUG\"]\n",
    "    s2_names = [name for (name, word_type) in s2_features if word_type == \"DRUG\"]\n",
    "    \n",
    "    # check if drug name is in common\n",
    "    shared_drug = list(set(s1_names) & set(s2_names))\n",
    "    \n",
    "    # share drug name, but linkers are different\n",
    "    if shared_drug != [] and s1_features != s2_features:\n",
    "        return 1\n",
    "    else: \n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee3a2a4-161d-4f76-840b-858e85641194",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Use above methods to get features for data\n",
    "s1, s2 are Sentence instances\n",
    "\"\"\"\n",
    "def get_feature_df(s1, s2, label, conflict_type, pair_id):\n",
    "    sentence_1 = s1.txt\n",
    "    sentence_2 = s2.txt\n",
    "#     sentence_df = create_sentence_encoding(sentence_1, sentence_2)\n",
    "    \n",
    "    # check negation in docs\n",
    "    neg_check_umls = check_if_number_neg_equal_umls(s1, s2)\n",
    "\n",
    "    # check shared features in UMLS and Med7\n",
    "    check_umls = check_shared_feature_umls(s1,s2)\n",
    "    check_med7 = check_shared_feature_med7(s1,s2)\n",
    "    \n",
    "    # find dependent children similarity\n",
    "    dep_similarity = create_dep_encoding(s1, s2)\n",
    "    \n",
    "    sentence_info = [neg_check_umls, check_umls, check_med7, \\\n",
    "                     sentence_1, sentence_2, dep_similarity, \\\n",
    "                     label, conflict_type, pair_id]\n",
    "    \n",
    "#     sentence_df[\"neg_check_umls\"] = neg_check_umls\n",
    "#     sentence_df[\"check_umls\"] = check_umls\n",
    "#     sentence_df[\"check_med7\"] = check_med7\n",
    "#     sentence_df[\"sentence_1\"] = sentence_1\n",
    "#     sentence_df[\"sentence_2\"] = sentence_2\n",
    "#     sentence_df[\"dep_sim\"] = dep_similarity\n",
    "\n",
    "#     # put contradiction label\n",
    "#     sentence_df[\"contradiction?\"] = label\n",
    "    \n",
    "#     # put pair_id for reference\n",
    "#     sentence_df[\"conflict_type\"] = conflict_type\n",
    "#     sentence_df[\"pair_id\"] = pair_id\n",
    "    return sentence_info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a36d0b64-fdbf-40c7-8f43-9424ef791f46",
   "metadata": {},
   "source": [
    "### Scaling up features for generated dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a78a55-3bca-4741-a574-a5c6eff0b0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# total_features_df = pd.DataFrame()\n",
    "total_features = []\n",
    "\n",
    "for pair_id in tqdm(range(len(generated_dataset))):\n",
    "    (s1, s2), label, conflict_type = generated_dataset[pair_id]\n",
    "    features = get_feature_df(s1, s2, label, conflict_type, pair_id)\n",
    "#     total_features_df = pd.concat((total_features_df, feature_df), axis=0)\n",
    "    total_features.append(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39772d5-a0e1-4072-8632-778975b922f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = \\\n",
    "[\"neg_check_umls\", \"check_umls\", \"check_med7\", \\\n",
    "     \"sentence_1\", \"sentence_2\", \"dep_sim\", \"contradiction?\", \\\n",
    "     \"conflict_type\", \"pair_id\"]\n",
    "\n",
    "\n",
    "total_features_df = pd.DataFrame(total_features, columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ee39d9-6c63-471d-9fc3-0d9d6aaacb2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_features_df.to_csv(\"generated_features.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8aeb820-8e01-4825-ab3b-f148dc810357",
   "metadata": {},
   "source": [
    "# 6. Load and process hand-labeled MIMIC data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36cbcb74-24b0-462c-9ce1-77eb7feb652b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DailyDataNull(object):\n",
    "    \"\"\" Placeholder for DailyData (e.g. Note, PrescriptionOrder, LabResults) \"\"\"\n",
    "    def __init__(self, umls, rxnorm, med7, umls_linker, rxnorm_linker):\n",
    "        self.umls   = umls\n",
    "        self.rxnorm = rxnorm\n",
    "        self.med7   = med7\n",
    "        \n",
    "        self.umls_linker   = umls_linker\n",
    "        self.rxnorm_linker = rxnorm_linker\n",
    "        \n",
    "        self.time = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5702a6-54b6-4a71-aacd-9e73021ca848",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e6ae7b-c44e-4a27-be6b-4731e07d2163",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load per pt data\n",
    "hand_labeled_dir = \"hand_labeled_data\"\n",
    "raw_data_list = []\n",
    "\n",
    "for xlsx_file in os.listdir(hand_labeled_dir):\n",
    "    hadm_id = xlsx_file.split('.')[0]\n",
    "    \n",
    "    try: # skip non pt id data\n",
    "        hadm_id_int = int(hadm_id)\n",
    "    except ValueError:\n",
    "        continue\n",
    "    \n",
    "    data_xls = pd.read_excel(os.path.join(hand_labeled_dir, xlsx_file), hadm_id)\n",
    "    data_xls['hadm_id'] = hadm_id_int\n",
    "    \n",
    "    raw_data_list.append(data_xls)\n",
    "    \n",
    "labeled_setA_df = pd.concat(raw_data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c707306-8552-4d94-9190-b86d4767c4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load from google doc data\n",
    "gdoc_data_file = 'from_google_doc_samedayonly.xlsx'\n",
    "labeled_setB_df = pd.read_excel(os.path.join(hand_labeled_dir, gdoc_data_file), '129414') # just random sheet name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fcc7ea0-6041-497c-8536-f9e6dec8cb00",
   "metadata": {},
   "outputs": [],
   "source": [
    "row['label'] == -1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75384764-7027-4ff1-a48b-948fa0472567",
   "metadata": {},
   "source": [
    "## Process the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd33e8d-910f-45b8-8e13-c04680029588",
   "metadata": {},
   "outputs": [],
   "source": [
    "nullnote = DailyDataNull(umls_nlp, rxnorm_nlp, med7_nlp,\n",
    "                         umls_linker, rxnorm_linker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c0b9d9-1997-4dbe-9aec-ced15fbfde3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "hand_labeled_datas = [] # list of tuples ((s1, s2), label)\n",
    "\n",
    "# Process set A\n",
    "for _, row in tqdm(labeled_setA_df.iterrows()): # iterate over sentence pairs\n",
    "    s1_txt = row['sentence 1']\n",
    "    s2_txt = row['sentence 2']\n",
    "    hadm_id = row['hadm_id']\n",
    "    label   = row['label']\n",
    "    \n",
    "    if label == -1:\n",
    "        continue\n",
    "        \n",
    "    # create the sentences\n",
    "    sentence1 = Sentence(nullnote, None,\n",
    "                         filter_map=SEMANTIC_TYPE_TO_NAME,\n",
    "                         conflict_map=CONFLICT_TO_SEMANTIC_TYPE,\n",
    "                         sentence=s1_txt)\n",
    "    sentence2 = Sentence(nullnote, None,\n",
    "                         filter_map=SEMANTIC_TYPE_TO_NAME,\n",
    "                         conflict_map=CONFLICT_TO_SEMANTIC_TYPE,\n",
    "                         sentence=s2_txt)\n",
    "    \n",
    "    hand_labeled_datas.append(((sentence1, sentence2), label, hadm_id))\n",
    "    \n",
    "\n",
    "# Process set B\n",
    "for _, row in tqdm(labeled_setB_df.iterrows()): # iterate over sentence pairs\n",
    "    s1_txt = row['Sentence 1']\n",
    "    s2_txt = row['Sentence 2']\n",
    "    hadm_id = row['Hadm_id']\n",
    "    label   = row['label']\n",
    "    \n",
    "    if label == -1:\n",
    "        continue\n",
    "        \n",
    "    # create the sentences\n",
    "    sentence1 = Sentence(nullnote, None,\n",
    "                         filter_map=SEMANTIC_TYPE_TO_NAME,\n",
    "                         conflict_map=CONFLICT_TO_SEMANTIC_TYPE,\n",
    "                         sentence=s1_txt)\n",
    "    sentence2 = Sentence(nullnote, None,\n",
    "                         filter_map=SEMANTIC_TYPE_TO_NAME,\n",
    "                         conflict_map=CONFLICT_TO_SEMANTIC_TYPE,\n",
    "                         sentence=s2_txt)\n",
    "    \n",
    "    hand_labeled_datas.append(((sentence1, sentence2), label, hadm_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1692e253-3d2a-40a2-b580-2c660d7d61dd",
   "metadata": {},
   "source": [
    "## Feature Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b692e2c6-fbeb-463d-81cd-a6809f46bd73",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_diagnosis = lambda stype: stype in CONFLICT_TO_SEMANTIC_TYPE['diagnosis']\n",
    "is_med       = lambda stype: stype in CONFLICT_TO_SEMANTIC_TYPE['med_allergy']\n",
    "is_test      = lambda stype: stype in CONFLICT_TO_SEMANTIC_TYPE['test_results']\n",
    "\n",
    "def get_conflict_type(s1, s2):\n",
    "    conflict_types = []\n",
    "    \n",
    "    is_diag_s1 = any([is_diagnosis(stype) for stype in s1.semantic_types])\n",
    "    is_diag_s2 = any([is_diagnosis(stype) for stype in s2.semantic_types])\n",
    "    if is_diag_s1 and is_diag_s2: conflict_types.append(\"diagnosis\")\n",
    "\n",
    "    is_med_s1 = any([is_med(stype) for stype in s1.semantic_types])\n",
    "    is_med_s2 = any([is_med(stype) for stype in s2.semantic_types])\n",
    "    if is_med_s1 and is_med_s2: conflict_types.append(\"med\")\n",
    "\n",
    "    is_test_s1 = any([is_test(stype) for stype in s1.semantic_types])\n",
    "    is_test_s2 = any([is_test(stype) for stype in s2.semantic_types])\n",
    "    if is_test_s1 and is_test_s2: conflict_types.append(\"test\")\n",
    "        \n",
    "    return conflict_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9881fb35-3c8c-4908-9855-305c2fb0be28",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Use above methods to get features for data\n",
    "s1, s2 are Sentence instances\n",
    "\"\"\"\n",
    "def get_feature_df_mimic(s1, s2, hadm_id, pair_id, label):\n",
    "    sentence_1 = s1.txt\n",
    "    sentence_2 = s2.txt\n",
    "    \n",
    "    # check negation in docs\n",
    "    neg_check_umls = check_if_number_neg_equal_umls(s1, s2)\n",
    "\n",
    "    # check shared features in UMLS and Med7\n",
    "    check_umls = check_shared_feature_umls(s1,s2)\n",
    "    check_med7 = check_shared_feature_med7(s1,s2)\n",
    "    \n",
    "    # find dependent children similarity\n",
    "    dep_similarity = create_dep_encoding(s1, s2)\n",
    "    \n",
    "    # get conflict type -- returns list \n",
    "    conflict_type = get_conflict_type(s1, s2)\n",
    "    \n",
    "    sentence_info = [neg_check_umls, check_umls, check_med7, \\\n",
    "                     sentence_1, sentence_2, dep_similarity, \\\n",
    "                     hadm_id, conflict_type, pair_id, label]\n",
    "    \n",
    "    return sentence_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f323fdd-b349-451e-a666-5641c1787043",
   "metadata": {},
   "outputs": [],
   "source": [
    "# total_features_df = pd.DataFrame()\n",
    "hand_labeled_features = []\n",
    "\n",
    "for pair_id in tqdm(range(len(hand_labeled_datas))):\n",
    "    (s1, s2), label, hadm_id = hand_labeled_datas[pair_id]\n",
    "    features = get_feature_df_mimic(s1, s2, hadm_id, pair_id, label)\n",
    "    hand_labeled_features.append(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad304cb4-3170-47ff-89b9-cdc891401aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = \\\n",
    "[\"neg_check_umls\", \"check_umls\", \"check_med7\", \\\n",
    "     \"sentence_1\", \"sentence_2\", \"dep_sim\", \\\n",
    "     \"hadm_id\", \"conflict_type\", \"pair_id\", \"contradiction?\"]\n",
    "\n",
    "\n",
    "hand_labeled_features_df = pd.DataFrame(hand_labeled_features, columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e7b99f-917f-4d1b-a31a-97035d1a11e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "hand_labeled_features_df.to_csv(\"hand_labeled_mimic_features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7b5292-315b-49b4-ad44-bbe3f64c9af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "hand_labeled_features_df.hadm_id.unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f56b3aa-7773-4648-a285-fe7602af10a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "hand_labeled_features_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f4328f-addd-4c5a-86bd-f8434e78458f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fc39415e-3868-4c41-bb29-97cf87f5c05b",
   "metadata": {},
   "source": [
    "# 7. Generating evaluation data (unlabeled) from MIMIC\n",
    "\n",
    "We'll avoid the first 10 patients since they were used for generated contradictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4bc2e6-b26c-440a-ad48-dee0c9029ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_dir = \"processed\"\n",
    "os.makedirs(processed_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb38daaa-c4be-49ce-af1a-395124b8cd06",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "per_pat_dataset_dict = {} # maps HADMID to patient's dataset in the form [((data 1, data 2), label), ...]\n",
    "df_list = []\n",
    "for hadm_id in hadm_ids[10:20]:\n",
    "    print(\"***********************************\")\n",
    "    print(f\"Patient {int(hadm_id)}\")\n",
    "        \n",
    "    # Step 1: Select a patient -- process all data\n",
    "    pat = Patient(hadm_id, notes_df, drug_df, lab_df, d_lab_df, \\\n",
    "                  med7_nlp, umls_nlp, rxnorm_nlp, umls_linker, rxnorm_linker, \\\n",
    "                  physician_only=True)\n",
    "\n",
    "    # Step 2: Generate pairs for this patient\n",
    "    df, data_inst_pairs = generate_data_pairs(pat)\n",
    "    df['HADM_ID'] = hadm_id\n",
    "    per_pat_dataset_dict[hadm_id] = data_inst_pairs\n",
    "    df_list.append(df)\n",
    "    \n",
    "#     df.to_csv(f\"{processed_dir}/{int(hadm_id)}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f18999-137a-4372-9e5d-560f5d7efdea",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = pd.concat(df_list)\n",
    "\n",
    "df.to_csv(f\"{processed_dir}/mimic_qual_eval.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de3758d5-80bf-4e69-9551-b4161c559924",
   "metadata": {},
   "source": [
    "## Feature Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0baf5d5-2204-4fcf-a9ce-cf4c1888827e",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_diagnosis = lambda stype: stype in CONFLICT_TO_SEMANTIC_TYPE['diagnosis']\n",
    "is_med       = lambda stype: stype in CONFLICT_TO_SEMANTIC_TYPE['med_allergy']\n",
    "is_test      = lambda stype: stype in CONFLICT_TO_SEMANTIC_TYPE['test_results']\n",
    "\n",
    "def get_conflict_type(s1, s2):\n",
    "    conflict_types = []\n",
    "    \n",
    "    is_diag_s1 = any([is_diagnosis(stype) for stype in s1.semantic_types])\n",
    "    is_diag_s2 = any([is_diagnosis(stype) for stype in s2.semantic_types])\n",
    "    if is_diag_s1 and is_diag_s2: conflict_types.append(\"diagnosis\")\n",
    "\n",
    "    is_med_s1 = any([is_med(stype) for stype in s1.semantic_types])\n",
    "    is_med_s2 = any([is_med(stype) for stype in s2.semantic_types])\n",
    "    if is_med_s1 and is_med_s2: conflict_types.append(\"med\")\n",
    "\n",
    "    is_test_s1 = any([is_test(stype) for stype in s1.semantic_types])\n",
    "    is_test_s2 = any([is_test(stype) for stype in s2.semantic_types])\n",
    "    if is_test_s1 and is_test_s2: conflict_types.append(\"test\")\n",
    "        \n",
    "    return conflict_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb80113-7825-47c9-a84b-7cf5b789e3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Use above methods to get features for data\n",
    "s1, s2 are Sentence instances\n",
    "\"\"\"\n",
    "def get_feature_df_mimic(s1, s2, hadm_id, pair_id):\n",
    "    sentence_1 = s1.txt\n",
    "    sentence_2 = s2.txt\n",
    "    \n",
    "    # check negation in docs\n",
    "    neg_check_umls = check_if_number_neg_equal_umls(s1, s2)\n",
    "\n",
    "    # check shared features in UMLS and Med7\n",
    "    check_umls = check_shared_feature_umls(s1,s2)\n",
    "    check_med7 = check_shared_feature_med7(s1,s2)\n",
    "    \n",
    "    # find dependent children similarity\n",
    "    dep_similarity = create_dep_encoding(s1, s2)\n",
    "    \n",
    "    # get conflict type -- returns list \n",
    "    conflict_type = get_conflict_type(s1, s2)\n",
    "    \n",
    "    sentence_info = [neg_check_umls, check_umls, check_med7, \\\n",
    "                     sentence_1, sentence_2, dep_similarity, \\\n",
    "                     hadm_id, conflict_type, pair_id]\n",
    "    \n",
    "    return sentence_info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278e1782-9f16-4e9d-a524-0ee2ac9d048f",
   "metadata": {},
   "source": [
    "### Scaling up features for generated dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d0f1a3-3d69-4eb0-ac6e-68391f1332d5",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# total_features_df = pd.DataFrame()\n",
    "total_features = []\n",
    "\n",
    "for hadm_id, hadm_mimic_dataset in per_pat_dataset_dict.items():\n",
    "    print(f\"Processing patient {int(hadm_id)}\")\n",
    "    for pair_id in tqdm(range(len(hadm_mimic_dataset))):\n",
    "        (s1, s2), _ = hadm_mimic_dataset[pair_id]\n",
    "        features = get_feature_df_mimic(s1, s2, hadm_id, pair_id)\n",
    "        total_features.append(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf75964-6aaf-42ba-af87-e1526d83810a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = \\\n",
    "[\"neg_check_umls\", \"check_umls\", \"check_med7\", \\\n",
    "     \"sentence_1\", \"sentence_2\", \"dep_sim\", \\\n",
    "     \"hadm_id\", \"conflict_type\", \"pair_id\"]\n",
    "\n",
    "mimic_total_features_df = pd.DataFrame(total_features, columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e8345f-a9f2-4a69-91c2-44e8f120a8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mimic_total_features_df.to_csv(\"mimic_features.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bcc42a7-c6d6-4386-8b5d-71119fc14201",
   "metadata": {},
   "source": [
    "### Getting History + Allergy Information - @Sharon, you can ignore everytihng below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2c644e-d063-4e7b-b2f8-aff9b2b4e13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo: \n",
    "# - DONE function to re-process all data from Patient instance -- pat.process_notes(); pat.process_by_date()\n",
    "# - function to update Note -- should update dataframe of patient directly\n",
    "#   - can go back to dataframe, but can't map tokenized sentence to original note in df -- todo\n",
    "#   - function to update tokenized sentence\n",
    "# - later: function to update original dataframe from patient dataframe\n",
    "\n",
    "import re\n",
    "\n",
    "def get_section(regex_dict, txt):\n",
    "    \"\"\" Given a dictionary of start and end regex's for a\n",
    "        particular section, gets the start and endpoint of \n",
    "        section in the text and returns indices. \n",
    "        Returns None if section does not exist.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        start    = re.search(regex_dict[\"start\"], txt).start()\n",
    "        end      = re.search(regex_dict[\"end\"],   txt).start()\n",
    "    except AttributeError:\n",
    "        start, end = None, None\n",
    "    \n",
    "    return start, end\n",
    "\n",
    "note = pat.notes[4]\n",
    "\n",
    "# Sections to store \n",
    "# note: most of these sections have already been removed,\n",
    "#       but if they haven't might have to remove then \n",
    "#       reprocess everything\n",
    "allergy_regex = {\"start\": \"Allergies:\",\n",
    "                 \"end\":   \"Last dose of Antibiotics:\"}\n",
    "history_regex = {\"start\": \"Past medical history:\",\n",
    "                 \"end\":   \"Other:\"}\n",
    "\n",
    "allergy_start, allergy_end = get_section(allergy_regex, note.txt)\n",
    "history_start, history_end = get_section(history_regex, note.txt)\n",
    "\n",
    "pt_allergies = \"\" if allergy_start is None else note.txt[allergy_start:allergy_end]\n",
    "pt_histories = \"\" if history_start is None else note.txt[history_start:history_end]\n",
    "\n",
    "print(\"******** Allergies ********\")\n",
    "print(pt_allergies[:100])\n",
    "print(\"******** Histories ********\")\n",
    "print(pt_histories[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc60d0b-c7ac-4d27-b7e7-e3e74364ac1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932b6cfc-f97a-420e-8595-b968eeb2b1af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00fbb6c9-c30b-4b79-a535-7f95b7206ff7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c65a86-d9b7-4e26-a29b-fdf860d1a4a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf3857b-30b6-4c07-867c-6041a9622c2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c45ea67-a917-4878-aa1e-d86b4c33ee5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715515ef-169b-4d6a-aafe-43ee09fdccae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c391c1-51ca-420c-a693-d746da2adcce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
