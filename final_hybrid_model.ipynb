{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "final_hybrid_model.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "j0KzrYXsevxl"
      },
      "source": [
        "!pip install spacy==2.3.5\n",
        "!pip install scispacy==0.3.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "67h9_xP2e65g"
      },
      "source": [
        "import spacy\n",
        "import scispacy\n",
        "\n",
        "from pprint import pprint\n",
        "from collections import OrderedDict\n",
        "import pandas as pd\n",
        "\n",
        "from spacy import displacy\n",
        "from scispacy.umls_linking import UmlsEntityLinker\n",
        "\n",
        "from sklearn.base import BaseEstimator\n",
        "from typing import Dict, Tuple\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "# Standard Imports\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "\n",
        "# Transformers\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler, MinMaxScaler\n",
        "\n",
        "# Modeling Evaluation\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, KFold, GridSearchCV\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score,f1_score, confusion_matrix, classification_report\n",
        "from IPython.display import display, Markdown\n",
        "\n",
        "\n",
        "# should be 2.3.5 and >=0.3.0\n",
        "spacy.__version__, scispacy.__version__"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wS5mTJPRe4Zc"
      },
      "source": [
        "from google.colab import drive \n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HFa7R3gWgxp0"
      },
      "source": [
        "Read in structured data with relevant features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CVk8hhzge5x0"
      },
      "source": [
        "# split labeled data into training, testing sets\n",
        "train_df = pd.read_csv(\"gdrive/MyDrive/6.871/train_features.csv\")\n",
        "dev_df = pd.read_csv(\"gdrive/MyDrive/6.871/dev_features.csv\")\n",
        "test_df = pd.read_csv(\"gdrive/MyDrive/6.871/test_features.csv\")\n",
        "\n",
        "\n",
        "print(train_df)\n",
        "print(dev_df)\n",
        "print(test_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YgYuayOce8v3"
      },
      "source": [
        "# fill Na with 0 (bag of words)\n",
        "train_df = train_df.fillna(0)\n",
        "dev_df = dev_df.fillna(0)\n",
        "test_df = test_df.fillna(0)\n",
        "\n",
        "train_X = train_df.drop([\"Unnamed: 0\", 'pair_id', 'type_data'], axis=1)\n",
        "train_y = train_df[\"contradiction?\"]\n",
        "\n",
        "dev_X = dev_df.drop([\"Unnamed: 0\", 'pair_id', 'type_data'], axis=1)\n",
        "dev_y = dev_df[\"contradiction?\"]\n",
        "\n",
        "test_X = test_df.drop([\"Unnamed: 0\",'pair_id', 'type_data'], axis=1)\n",
        "test_y = test_df[\"contradiction?\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HuFVC4Ozg2G2"
      },
      "source": [
        "Establish rules to explore as relevant features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rMHxanE8fDZX"
      },
      "source": [
        "# RULES:\n",
        "# check_umls: if they do not share a concept, return 1 (no contradiction)\n",
        "# neg_check_umls: if number of neg tokens is equal, return 0 (no contradiction); otherwise, return 1 (contradiction)\n",
        "# check_med7: if not talking about same DRUG -> return 0 (no contradiction); if same DRUG but different other info -> return 1 (contradiction)\n",
        "# dep_sim: if number < 0.5 (contradiction)\n",
        "\n",
        "rules = {\"check_umls\": [\n",
        "                (\"=\", 1, 0.0)\n",
        "              ], \n",
        "        \"neg_check_umls\": [\n",
        "                (\"=\", 1, 1.0)\n",
        "              ],\n",
        "         \"check_med7\": [\n",
        "                (\"=\", 1, 1.0)\n",
        "              ],\n",
        "         \"dep_sim\": [\n",
        "                (\"<\", 0.5, 1.0)\n",
        "              ]\n",
        "        }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r5P_Od4-gsXj"
      },
      "source": [
        "Hybrid rule-based learning with auto learned rules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hHq5-HyZfK-4"
      },
      "source": [
        "class RuleAugmentedEstimator(BaseEstimator):\n",
        "  \"\"\"\n",
        "  Augments sklearn estimators with deterministic rule-based logic.\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, base_model: BaseEstimator, rules: Dict, **base_params):\n",
        "      \"\"\"\n",
        "      Initializes the rule-augmented estimator by supplying underlying sklearn estimator\n",
        "      and hard-coded rules.\n",
        "\n",
        "      Args:\n",
        "        base_model: underlying sklearn estimator.\n",
        "          Must implement fit and predict method.\n",
        "        rules: hard coded rules in format of dictionary,\n",
        "          with keys being the pandas dataframe column name, \n",
        "          and values being a tuple in the following form: \n",
        "          (comparison operator, value, return value)\n",
        "\n",
        "          Acceptable comparison operators are: \n",
        "          \"=\", \"<\", \">\", \"<=\", \">=\"\n",
        "\n",
        "          Example:\n",
        "                \n",
        "                {\"House Type\": [\n",
        "                    (\"=\", \"Penthouse\", 1.0),\n",
        "                    (\"=\", \"Shack\", 0.0)\n",
        "                  ],\n",
        "                  \"House Price\": [\n",
        "                      (\"<\", 1000.0, 0.0),\n",
        "                      (\">=\", 500000.0, 1.0)\n",
        "                ]}\n",
        "        **base_params: Optional keyword arguments which will be passed on\n",
        "            to the base_model.\n",
        "\n",
        "      \"\"\"\n",
        "      self.rules = rules\n",
        "      self.base_model = base_model\n",
        "      self.base_model.set_params(**base_params)\n",
        "\n",
        "  def __repr__(self):\n",
        "      return \"Rule Augmented Estimator:\\n\\n\\t Base Model: {}\\n\\t Rules: {}\".format(self.base_model, self.rules)\n",
        "\n",
        "  def __str__(self):\n",
        "      return self.__str__\n",
        "\n",
        "  def _get_base_model_data(self, X: pd.DataFrame, y: pd.Series) -> Tuple[pd.DataFrame, pd.Series]:\n",
        "      \"\"\"\n",
        "      Filters the training data for data points not affected by the rules.\n",
        "      \"\"\"\n",
        "      train_x = X\n",
        "\n",
        "      for category, rules in self.rules.items():\n",
        "\n",
        "          if category not in train_x.columns.values: continue\n",
        "\n",
        "          for rule in rules:\n",
        "\n",
        "              if rule[0] == \"=\":\n",
        "                  train_x = train_x.loc[train_x[category] != rule[1]]\n",
        "\n",
        "              elif rule[0] == \"<\":\n",
        "                  train_x = train_x.loc[train_x[category] >= rule[1]]\n",
        "\n",
        "              elif rule[0] == \">\":\n",
        "                  train_x = train_x.loc[train_x[category] <= rule[1]]\n",
        "\n",
        "              elif rule[0] == \"<=\":\n",
        "                  train_x = train_x.loc[train_x[category] > rule[1]]\n",
        "\n",
        "              elif rule[0] == \">=\":\n",
        "                  train_x = train_x.loc[train_x[category] < rule[1]]\n",
        "\n",
        "              else:\n",
        "                  print(\"Invalid rule detected: {}\".format(rule))\n",
        "              \n",
        "      indices = train_x.index.values\n",
        "      train_y = y.iloc[indices]\n",
        "      \n",
        "      train_x = train_x.reset_index(drop=True)\n",
        "      train_y = train_y.reset_index(drop=True)\n",
        "      \n",
        "      return train_x, train_y   \n",
        "\n",
        "  def fit(self, X: pd.DataFrame, y: pd.Series, **kwargs):\n",
        "      \"\"\"Fits the estimator to the data.\n",
        "      \n",
        "      Fits the estimator to the data, only training the underlying estimator\n",
        "      on data which isn't affected by the hard-coded rules.\n",
        "      \n",
        "      Args:\n",
        "          X: The training feature data.\n",
        "          y: The training label data.\n",
        "          **kwargs: Optional keyword arguments passed to the underlying\n",
        "          estimator's fit function.\n",
        "              \n",
        "      \"\"\"\n",
        "      train_x, train_y = self._get_base_model_data(X, y)\n",
        "      self.base_model.fit(train_x, train_y, **kwargs)\n",
        "\n",
        "  def predict(self, X: pd.DataFrame) -> np.array:\n",
        "      \"\"\"Gets predictions for the provided feature data.\n",
        "      \n",
        "      The predicitons are evaluated using the provided rules wherever possible\n",
        "      otherwise the underlying estimator is used.\n",
        "      \n",
        "      Args:\n",
        "          X: The feature data to evaluate predictions for.\n",
        "      \n",
        "      Returns:\n",
        "          np.array: Evaluated predictions.\n",
        "      \"\"\"\n",
        "      \n",
        "      p_X = X.copy()\n",
        "      p_X['prediction'] = np.nan\n",
        "\n",
        "      for category, rules in self.rules.items():\n",
        "\n",
        "          if category not in p_X.columns.values: continue\n",
        "\n",
        "          for rule in rules:\n",
        "\n",
        "              if rule[0] == \"=\":\n",
        "                  p_X.loc[p_X[category] == rule[1], 'prediction'] = rule[2]\n",
        "\n",
        "              elif rule[0] == \"<\":\n",
        "                  p_X.loc[p_X[category] < rule[1], 'prediction'] = rule[2]\n",
        "\n",
        "              elif rule[0] == \">\":\n",
        "                  p_X.loc[p_X[category] > rule[1], 'prediction'] = rule[2]\n",
        "\n",
        "              elif rule[0] == \"<=\":\n",
        "                  p_X.loc[p_X[category] <= rule[1], 'prediction'] = rule[2]\n",
        "\n",
        "              elif rule[0] == \">=\":\n",
        "                  p_X.loc[p_X[category] >= rule[1], 'prediction'] = rule[2]\n",
        "\n",
        "              else:\n",
        "                  print(\"Invalid rule detected: {}\".format(rule))\n",
        "\n",
        "      if len(p_X.loc[p_X['prediction'].isna()].index != 0):\n",
        "\n",
        "          base_X = p_X.loc[p_X['prediction'].isna()].copy()\n",
        "          base_X.drop('prediction', axis=1, inplace=True)\n",
        "          p_X.loc[p_X['prediction'].isna(), 'prediction'] = self.base_model.predict(base_X)\n",
        "\n",
        "      return p_X['prediction'].values\n",
        "    \n",
        "  def get_params(self, deep: bool = True) -> Dict:\n",
        "      \"\"\"Return the model's and base model's parameters.\n",
        "      Args:\n",
        "          deep: Whether to recursively return the base model's parameters.\n",
        "      Returns\n",
        "          Dict: The model's parameters.\n",
        "      \"\"\"\n",
        "      \n",
        "      params = {'base_model': self.base_model,\n",
        "                'outcome_range': self.outcome_range,\n",
        "                'rules': self.rules\n",
        "                }\n",
        "\n",
        "      params.update(self.base_model.get_params(deep=deep))\n",
        "      return params\n",
        "    \n",
        "  def set_params(self, **params):\n",
        "      \"\"\"Sets parameters for the model and base model.\n",
        "      Args:\n",
        "          **params: Optional keyword arguments.\n",
        "      \"\"\"\n",
        "                \n",
        "      parameters = params\n",
        "      param_keys = parameters.keys()\n",
        "      \n",
        "      if 'base_model' in param_keys:\n",
        "          value = parameters.pop('base_model')\n",
        "          self.base_model = value"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bLlam_0TfbvF"
      },
      "source": [
        "# extract relevant features for rules\n",
        "auto_train_X = train_X[['check_umls', 'neg_check_umls', \"check_med7\",\"dep_sim\"]].copy()\n",
        "auto_test_X = test_X[['check_umls', 'neg_check_umls', \"check_med7\",\"dep_sim\"]].copy()\n",
        "print(auto_train_X)\n",
        "print(auto_test_X)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-KX5q3KXfsJ8"
      },
      "source": [
        "# fit the hybrid model with relevant features\n",
        "gbc = GradientBoostingClassifier(n_estimators=50, verbose=1)\n",
        "hybrid_model = RuleAugmentedEstimator(gbc, rules)\n",
        "hybrid_model.fit(auto_train_X, train_y)\n",
        "predictions = hybrid_model.predict(auto_test_X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Bp43BfJf2Ll"
      },
      "source": [
        "def evaluation(y, y_hat, title = 'Confusion Matrix'):\n",
        "    cm = confusion_matrix(y, y_hat)\n",
        "    precision = precision_score(y, y_hat)\n",
        "    recall = recall_score(y, y_hat)\n",
        "    accuracy = accuracy_score(y,y_hat)\n",
        "    f1 = f1_score(y,y_hat)\n",
        "    print('Recall: ', recall)\n",
        "    print('Accuracy: ', accuracy)\n",
        "    print('Precision: ', precision)\n",
        "    print('F1: ', f1)\n",
        "    sns.heatmap(cm,  cmap= 'PuBu', annot=True, fmt='g', annot_kws=    {'size':20})\n",
        "    plt.xlabel('predicted', fontsize=18)\n",
        "    plt.ylabel('actual', fontsize=18)\n",
        "    plt.title(title, fontsize=18)\n",
        "    \n",
        "    plt.show();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FkmYEslyf5H_"
      },
      "source": [
        "evaluation(y_true, predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hfsxW-j-f_gd"
      },
      "source": [
        "Rule based model only"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ILyREGA2gF76"
      },
      "source": [
        "class RuleBasedEstimator(BaseEstimator):\n",
        "  \"\"\"\n",
        "  Uses deterministic rule-based logic.\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, base_model: BaseEstimator, rules: Dict, **base_params):\n",
        "      \"\"\"\n",
        "      Initializes the rule-based estimator by supplying hard-coded rules.\n",
        "\n",
        "      Args:\n",
        "        base_model: underlying sklearn estimator.\n",
        "          Must implement fit and predict method.\n",
        "        rules: hard coded rules in format of dictionary,\n",
        "          with keys being the pandas dataframe column name, \n",
        "          and values being a tuple in the following form: \n",
        "          (comparison operator, value, return value)\n",
        "\n",
        "          Acceptable comparison operators are: \n",
        "          \"=\", \"<\", \">\", \"<=\", \">=\"\n",
        "\n",
        "          Example:\n",
        "                \n",
        "                {\"House Type\": [\n",
        "                    (\"=\", \"Penthouse\", 1.0),\n",
        "                    (\"=\", \"Shack\", 0.0)\n",
        "                  ],\n",
        "                  \"House Price\": [\n",
        "                      (\"<\", 1000.0, 0.0),\n",
        "                      (\">=\", 500000.0, 1.0)\n",
        "                ]}\n",
        "        **base_params: Optional keyword arguments which will be passed on\n",
        "            to the base_model.\n",
        "\n",
        "      \"\"\"\n",
        "      self.rules = rules\n",
        "      self.base_model = base_model\n",
        "      self.base_model.set_params(**base_params)\n",
        "\n",
        "  def __repr__(self):\n",
        "      return \"Rule Augmented Estimator:\\n\\n\\t Base Model: {}\\n\\t Rules: {}\".format(self.base_model, self.rules)\n",
        "\n",
        "  def __str__(self):\n",
        "      return self.__str__\n",
        "  \n",
        "\n",
        "  def fit(self, X: pd.DataFrame, y: pd.Series, **kwargs):\n",
        "      \"\"\"Fits the estimator to the data.\n",
        "      \n",
        "      Fits the estimator to the data, only training the underlying estimator\n",
        "      on data which isn't affected by the hard-coded rules.\n",
        "      \n",
        "      Args:\n",
        "          X: The training feature data.\n",
        "          y: The training label data.\n",
        "          **kwargs: Optional keyword arguments passed to the underlying\n",
        "          estimator's fit function.\n",
        "              \n",
        "      \"\"\"\n",
        "      self.base_model.fit(X, y, **kwargs)\n",
        "\n",
        "  def predict(self, X: pd.DataFrame) -> np.array:\n",
        "      \"\"\"Gets predictions for the provided feature data.\n",
        "      \n",
        "      The predicitons are evaluated using the provided rules wherever possible\n",
        "      otherwise the underlying estimator is used.\n",
        "      \n",
        "      Args:\n",
        "          X: The feature data to evaluate predictions for.\n",
        "      \n",
        "      Returns:\n",
        "          np.array: Evaluated predictions.\n",
        "      \"\"\"\n",
        "      \n",
        "      p_X = X.copy()\n",
        "      p_X['prediction'] = np.nan\n",
        "\n",
        "      for category, rules in self.rules.items():\n",
        "\n",
        "          if category not in p_X.columns.values: continue\n",
        "\n",
        "          for rule in rules:\n",
        "\n",
        "              if rule[0] == \"=\":\n",
        "                  p_X.loc[p_X[category] == rule[1], 'prediction'] = rule[2]\n",
        "\n",
        "              elif rule[0] == \"<\":\n",
        "                  p_X.loc[p_X[category] < rule[1], 'prediction'] = rule[2]\n",
        "\n",
        "              elif rule[0] == \">\":\n",
        "                  p_X.loc[p_X[category] > rule[1], 'prediction'] = rule[2]\n",
        "\n",
        "              elif rule[0] == \"<=\":\n",
        "                  p_X.loc[p_X[category] <= rule[1], 'prediction'] = rule[2]\n",
        "\n",
        "              elif rule[0] == \">=\":\n",
        "                  p_X.loc[p_X[category] >= rule[1], 'prediction'] = rule[2]\n",
        "\n",
        "              else:\n",
        "                  print(\"Invalid rule detected: {}\".format(rule))\n",
        "\n",
        "      # check if any predictions missing (relegate to base_model)\n",
        "      if len(p_X.loc[p_X['prediction'].isna()].index != 0):\n",
        "\n",
        "          base_X = p_X.loc[p_X['prediction'].isna()].copy()\n",
        "          base_X.drop('prediction', axis=1, inplace=True)\n",
        "          p_X.loc[p_X['prediction'].isna(), 'prediction'] = self.base_model.predict(base_X)\n",
        "\n",
        "      return p_X['prediction'].values\n",
        "    \n",
        "\n",
        "  def get_params(self, deep: bool = True) -> Dict:\n",
        "      \"\"\"Return the model's and base model's parameters.\n",
        "      Args:\n",
        "          deep: Whether to recursively return the base model's parameters.\n",
        "      Returns\n",
        "          Dict: The model's parameters.\n",
        "      \"\"\"\n",
        "      \n",
        "      params = {'base_model': self.base_model,\n",
        "                'outcome_range': self.outcome_range,\n",
        "                'rules': self.rules\n",
        "                }\n",
        "\n",
        "      params.update(self.base_model.get_params(deep=deep))\n",
        "      return params\n",
        "  \n",
        "\n",
        "  def set_params(self, **params):\n",
        "      \"\"\"Sets parameters for the model and base model.\n",
        "      Args:\n",
        "          **params: Optional keyword arguments.\n",
        "      \"\"\"\n",
        "                \n",
        "      parameters = params\n",
        "      param_keys = parameters.keys()\n",
        "      \n",
        "      if 'base_model' in param_keys:\n",
        "          value = parameters.pop('base_model')\n",
        "          self.base_model = value\n",
        "          \n",
        "      if 'rules' in param_keys:\n",
        "          value = parameters.pop('rules')\n",
        "          self.rules = value\n",
        "      \n",
        "      self.base_model.set_params(**parameters)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LpI9z3v5gB_i"
      },
      "source": [
        "# fit the rule based model with relevant features\n",
        "gbc = GradientBoostingClassifier(n_estimators=50, verbose=1)\n",
        "rule_model = RuleBasedEstimator(gbc, rules)\n",
        "rule_model.fit(auto_train_X, train_y)\n",
        "predictions = rule_model.predict(auto_test_X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FzkQtqu7gb8U"
      },
      "source": [
        "evaluation(y_true, predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QKXE4XQmgem6"
      },
      "source": [
        "Decision tree algorithm (gradient boosting classifier): auto learned rules only"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zelZttfIgi-t"
      },
      "source": [
        "gbc = GradientBoostingClassifier(n_estimators=50, verbose=1)\n",
        "gbc.fit(auto_train_X, train_y)\n",
        "predictions = gbc.predict(auto_test_X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4uLCsYxMgnVV"
      },
      "source": [
        "evaluation(y_true, predictions)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}